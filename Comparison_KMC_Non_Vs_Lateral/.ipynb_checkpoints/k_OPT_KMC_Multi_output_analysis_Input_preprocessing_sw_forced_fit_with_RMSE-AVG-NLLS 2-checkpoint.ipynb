{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224062de",
   "metadata": {},
   "source": [
    "***\n",
    "$$\\mathbf{\\text{Simulation/Experimental Output Processing and ML-MF Correction}}$$<br>\n",
    "$$\\mathbf{\\text{Author: Kenneth Kusima}}$$<br>\n",
    "$\\mathbf{\\text{Date: 06/01}}$<br>\n",
    "\n",
    "#### Note sw: Switching -> CO<->O2 ; CO*<->O* To match KMC specnum file\n",
    "\n",
    "\n",
    "#### It also |uses the MKM input files that match this order *_sw\n",
    "\n",
    "#### As well as the new test set KMC_NonDynamic_Data_iCovg_iRates_sw\n",
    "\n",
    "#### Switch the pressures accordingly CO <-> O2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf61d49",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Model being explored: Simple 4-step CO Oxidation}}:$<br>\n",
    "\n",
    "${\\text{Corresponding Micro Kinetic Model}}:$<br>\n",
    "***\n",
    "$$\\require{mhchem}$$       \n",
    "---\n",
    "Overall Reaction: \n",
    "$$ CO + \\frac{1}{2} O_2 {\\stackrel{\\tiny{\\textrm{Pt/Pd}}}{\\rightleftharpoons}} CO_2 $$\n",
    "---\n",
    "Note Reations in the Reaction Mechanism may be reversible or irreversible\n",
    "\n",
    "Reaction 1:&emsp;Adsorption of CO\n",
    "\n",
    "$$ CO + * \\rightleftharpoons CO^{*} $$\n",
    "\n",
    "Reaction 2:&emsp;Adsorption of $O_2$\n",
    "\n",
    "$$ O_2 + * \\rightleftharpoons {O_2}^{*} $$\n",
    "\n",
    "Reaction 3:&emsp;Dissociation of ${O_2}^*$ \n",
    "\n",
    "$$ {O_2}^* + * \\rightleftharpoons 2{O}^* $$\n",
    "\n",
    "Reaction 4:&emsp;Surface Reaction of $CO$ and $O_2$  \n",
    "\n",
    "$$ {CO}^{*} + {O}^{*} \\rightleftharpoons CO_2 + 2* $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675875ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bff0283",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a078f",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a><br>\n",
    " # Table of Contents  \n",
    "1. [Loading in the labeled simulation folders](#1)   \n",
    "    1. [Checking all simulations were completed as expected](#1.1)\n",
    "1. [Developing ML Training Dataset for rate correction](#2) \n",
    "    1. [Generating Experimental Data Dictionary](#2.1) \n",
    "    1. [Generating MF-MKM Data Dictionary](#2.2)     \n",
    "    1. [Creating Features](#2.3)      \n",
    "        C1. [Log ratio](#2.3.1)     \n",
    "        C2. [Percent Difference](#2.3.2)    \n",
    "        \n",
    "    1. [Creating Input/Feature Tensor](#2.4)\n",
    "    1. [Extracting Full X (Feature) and Y(Target) datasets](#2.5)\n",
    "    1. [Performing Train/Test X and Y Split datasets](#2.6)\n",
    "1. [Modelling](#3)\n",
    "1. [Describing Possible Machine Learning Model Algorithms](#4)\n",
    "1. [Selecting and Training the Model](#5)\n",
    "1. [Importing External/Experimental Data to be used in the model](#6)\n",
    "    1. [Generating corresponding MF-MKModel](#6.1) \n",
    "    1. [Predicting Machine-Learned Mean-Field Corrections](#6.2)\n",
    "    1. [ML Correction to MF-MKModel](#6.3)\n",
    "    1. [Evaluating the ML model prediction](#6.4)\n",
    "    1. [Plotting results](#6.5)\n",
    "    \n",
    "1. [Exploring and Evaluating possible ML options](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e78438",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"1\"></a> \n",
    "## 1. Loading in the labeled simulation folders\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4297924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/klkusima/Desktop/RASH_Research/CO_ox/Kinetics/OOP_Kinetics/MiKi/Comparison_KMC_Non_Vs_Lateral'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f1258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sim_folder_names_non = []\n",
    "# i = 0\n",
    "# for file in glob.glob(\"Sim_*_Non\"):\n",
    "#     Sim_folder_names_non.append(file)\n",
    "#     i+=1\n",
    "# print('Number of simulations:',i)\n",
    "# print(Sim_folder_names_non)\n",
    "#^ SINCE WE NEED TO MAKE SURE THE ORDER MATCHES\n",
    "\n",
    "Sim_folder_names_non = ['Sim_A_0_B_100_Non','Sim_A_100_B_0_Non','Sim_A_0_B_0_Non','Sim_A_44_B_44_Non']\n",
    "\n",
    "\n",
    "#os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec93a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sim_folder_names_lat = []\n",
    "# i = 0\n",
    "# for file in glob.glob(\"Sim_*_Lat\"):\n",
    "#     Sim_folder_names_lat.append(file)\n",
    "#     i+=1\n",
    "# print('Number of simulations:',i)\n",
    "# print(Sim_folder_names_lat)\n",
    "\n",
    "\n",
    "Sim_folder_names_lat = ['Sim_A_0_B_100_Lat','Sim_A_100_B_0_Lat','Sim_A_0_B_0_Lat','Sim_A_44_B_44_Lat']\n",
    "\n",
    "#os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b205d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_init_coverages = np.empty([len(Sim_folder_names_lat),4])\n",
    "#Remember: A='O*'; B='CO*'\n",
    "#Reading A and B initial coverages from the KMC simulation input coverage files\n",
    "c = 0 #counter\n",
    "for s in Sim_folder_names_lat:\n",
    "    set_coverages = []\n",
    "    for i in np.arange(len(s)):\n",
    "        if i<(len(s)-2) and s[i].isdigit() and (s[i+1]).isdigit() and (s[i+2]).isdigit():\n",
    "            cov_triple = int(s[i:i+3])\n",
    "            set_coverages.append(cov_triple)\n",
    "            \n",
    "        elif i<(len(s)-1) and s[i].isdigit() and (s[i+1]).isdigit()and not((s[i-1]).isdigit()):\n",
    "            cov_double = int(s[i:i+2])\n",
    "            set_coverages.append(cov_double)\n",
    "            \n",
    "#             print(cov_double)\n",
    "        elif s[i].isdigit() and not((s[i-1]).isdigit()) and not((s[i-2]).isdigit()):\n",
    "            cov_single = int(s[i])\n",
    "            set_coverages.append(cov_single)\n",
    "                                #B_O*_covg,     A_CO*_covg,     O2*_covg,*_covg\n",
    "    set_init_coverages[c,:] = [set_coverages[1],set_coverages[0],0,100-sum(set_coverages)]\n",
    "    c+=1 #counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b63683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/klkusima/Desktop/RASH_Research/CO_ox/Kinetics/OOP_Kinetics/MiKi/Comparison_KMC_Non_Vs_Lateral'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d67d57c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'specnum_output.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m Sim_folder_names_lat:\n\u001b[1;32m     12\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(s)\n\u001b[0;32m---> 13\u001b[0m     file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspecnum_output.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreadlines() \u001b[38;5;66;03m#Reading in the relevant file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     b\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(file)): \n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'specnum_output.txt'"
     ]
    }
   ],
   "source": [
    "#Checking to see match\n",
    "## Copying all the other input files into the different simulation folders\n",
    "# Extracting initial coverages\n",
    "#Remember: A='CO*'; B='O*'\n",
    "n_points = 500 #From KMC simulation \n",
    "n_gas_species = 3 #From KMC simulation\n",
    "n_surf_species = 4 #From KMC simulation\n",
    "\n",
    "Exp_init_coverages = np.empty([len(Sim_folder_names_lat),n_surf_species])\n",
    "c = 0 #counter\n",
    "for s in Sim_folder_names_lat:\n",
    "    os.chdir(s)\n",
    "    file=open('specnum_output.txt','r').readlines() #Reading in the relevant file\n",
    "    b=[]\n",
    "    for i in np.arange(len(file)): \n",
    "        b.append(file[i].split())                   #Dividing the rows into columns\n",
    "    o = pd.DataFrame(data=b)                        #Final output\n",
    "\n",
    "#     print(o)\n",
    "    #Extracting Number of Sites from the general_output file:\n",
    "    inp=open('general_output.txt','r').readlines()\n",
    "    for i in np.arange(len(inp)): \n",
    "        if 'Total number of lattice sites:' in inp[i]:\n",
    "            val = i  #Line in text file where sentence is present\n",
    "\n",
    "    sites = int(inp[val][35:])\n",
    "    \n",
    "    #Finding number of surface species\n",
    "    headings = (o.iloc[0,:])\n",
    "    n_ss = sum('*' in h for h in headings) #Number of surface species\n",
    "    \n",
    "    #Finding number of gas species\n",
    "    n_gs = len(headings)-5-n_ss\n",
    "    \n",
    "    #Adding column to calculate number of empty sites\n",
    "    n_c=(len(o.iloc[0,:])) #number of current columns\n",
    "    o[n_c]=\" \"           #Creating new empty column \n",
    "    o.iloc[0,n_c]=\"*\"    #Labelling the new empty column \n",
    "\n",
    "    st = 0 #Initializing empty site coverage vector\n",
    "\n",
    "\n",
    "    for i in range(len(o.iloc[1:])):\n",
    "        if n_ss==0:\n",
    "            site = sites\n",
    "        else:\n",
    "            for j in range(n_ss):\n",
    "                st = st + float(o.iloc[i+1,5+j]) #Calculating no. of empty sites #Asuming empty sites are first to be reportes (i.e @5)\n",
    "            site = sites - st\n",
    "            st = 0\n",
    "        o.iloc[i+1,n_c] = site\n",
    "    \n",
    "    Sspecies = []\n",
    "    for i in range(n_ss):\n",
    "        Sspecies.append(5+i) \n",
    "    Sspecies.append(len(o.iloc[1,:])-1)#Including empty sites\n",
    "\n",
    "    #Calculating itme:\n",
    "    Gtime = o[2][1:].astype(float) \n",
    "    #Calculating coverages:\n",
    "    Scoverages = np.empty([len(o.iloc[:,1])-1,len(Sspecies)])\n",
    "    for i in range(len(Scoverages[1,:])):\n",
    "        Scoverages[:,i] = o[Sspecies[i]][1:].astype(float)/sites\n",
    "        \n",
    "    exp_init_covg = []\n",
    "    for i in np.arange(n_surf_species):    #A_O*_covg,     B_CO*_covg,     O2*_covg, *_covg\n",
    "        exp_init_covg.append(Scoverages[0,i])\n",
    "        \n",
    "    Exp_init_coverages[c,:] = exp_init_covg\n",
    "    \n",
    "    c+=1\n",
    "    \n",
    "    \n",
    "    os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d061af",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a> \n",
    "## 1.1 Checking all simulations were completed as expected\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54239bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.shape(set_init_coverages) != np.shape(Exp_init_coverages):\n",
    "    raise Exception('Not all simulations have been completed successfully')\n",
    "    \n",
    "for i in np.arange(np.shape(set_init_coverages)[0]):\n",
    "    for j in np.arange(np.shape(set_init_coverages)[1]):\n",
    "        norm_val = set_init_coverages[i,j]\n",
    "        exp_val = round(Exp_init_coverages[i,j])\n",
    "        if not( norm_val + 1 > exp_val) and not(norm_val - 1 < exp_val): #i.e if not within range\n",
    "            raise Exception('Initial coverages used in the simulation are not the same as it was set')\n",
    "            \n",
    "        if (i==(np.shape(set_init_coverages)[0] - 1) and j==(np.shape(set_init_coverages)[1] - 1)):\n",
    "            print('SIMULATIONS MATCH AS EXPECTED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6afb0",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2\"></a> \n",
    "## 2. Developing ML Training Dataset for rate correction\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b1f8c",
   "metadata": {},
   "source": [
    "## Dictionary formats:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "676d8e3f",
   "metadata": {},
   "source": [
    "#Dictionaries to be used\n",
    "\n",
    "data_KMC_dict = {'init_covg': init_coverages, \n",
    "                    'sim_time': KMC_time_Array, \n",
    "                     'covg_prof': Covg, \n",
    "                     'iRates': Rates}\n",
    "         \n",
    "data_MKM_dict = {'init_covg': MKM_init_coverages, \n",
    "                    'sim_time': time_MKM_Array, \n",
    "                     'covg_prof': MKM_Covg, \n",
    "                     'iRates': MKM_Rates}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2477c7",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.1\"></a> \n",
    "## 2.A  Generating Experimental Data Dictionary\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6452c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e73cb",
   "metadata": {},
   "source": [
    "## FOR NON LATERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Copying all the other input files into the different simulation folders\n",
    "# Extracting initial coverages\n",
    "#Remember: A='O*'; B='CO*'\n",
    "n = len(Sim_folder_names_non)\n",
    "\n",
    "Covg = np.zeros((n,n_points,n_surf_species)) #O*, CO*, O2*, *\n",
    "Rates = np.zeros((n,n_points,n_gas_species)) #O2, CO, CO2\n",
    "KMC_time_Array = np.zeros((n,n_points))\n",
    "init_coverages = np.empty([n,n_surf_species])\n",
    "c = 0 #counter for number of simulation (folders)\n",
    "\n",
    "for s in Sim_folder_names_non:\n",
    "    os.chdir(s)\n",
    "    file=open('specnum_output.txt','r').readlines() #Reading in the relevant file\n",
    "    b=[]\n",
    "    for i in np.arange(len(file)): \n",
    "        b.append(file[i].split())                   #Dividing the rows into columns\n",
    "    o = pd.DataFrame(data=b)                        #Final output\n",
    "\n",
    "#     print(o)\n",
    "    #Extracting Number of Sites from the general_output file:\n",
    "    inp=open('general_output.txt','r').readlines()\n",
    "    for i in np.arange(len(inp)): \n",
    "        if 'Total number of lattice sites:' in inp[i]:\n",
    "            val = i  #Line in text file where sentence is present\n",
    "\n",
    "    sites = int(inp[val][34:])\n",
    "    \n",
    "    #Finding number of surface species\n",
    "    headings = (o.iloc[0,:])\n",
    "    n_ss = sum('*' in h for h in headings) #Number of surface species\n",
    "    \n",
    "    #Finding number of gas species\n",
    "    n_gs = len(headings)-5-n_ss\n",
    "    \n",
    "    #Adding column to calculate number of empty sites\n",
    "    n_c=(len(o.iloc[0,:])) #number of current columns\n",
    "    o[n_c]=\" \"           #Creating new empty column \n",
    "    o.iloc[0,n_c]=\"*\"    #Labelling the new empty column \n",
    "\n",
    "    st = 0 #Initializing empty site coverage vector\n",
    "\n",
    "\n",
    "    for i in range(len(o.iloc[1:])):\n",
    "        if n_ss==0:\n",
    "            site = sites\n",
    "        else:\n",
    "            for j in range(n_ss):\n",
    "                st = st + float(o.iloc[i+1,5+j]) #Calculating no. of empty sites #Asuming empty sites are first to be reportes (i.e @5)\n",
    "            site = sites - st\n",
    "            st = 0\n",
    "        o.iloc[i+1,n_c] = site\n",
    "    \n",
    "    Sspecies = []\n",
    "    for i in range(n_ss):\n",
    "        Sspecies.append(5+i) \n",
    "    Sspecies.append(len(o.iloc[1,:])-1)#Including empty sites\n",
    "\n",
    "    #Calculating itme:\n",
    "    Gtime = o[2][1:].astype(float) \n",
    "    \n",
    "    #Calculating coverages:\n",
    "    Scoverages = np.empty([len(o.iloc[:,1])-1,len(Sspecies)])\n",
    "    for i in range(len(Scoverages[1,:])):\n",
    "        Scoverages[:,i] = o[Sspecies[i]][1:].astype(float)/sites\n",
    "        \n",
    "    Gspecies = []\n",
    "    for i in range(n_gs):\n",
    "        Gspecies.append(5+n_ss+i) \n",
    "        \n",
    "    #Extracting the number of gas species molecules:    \n",
    "    Gnmol = np.empty([len(o.iloc[:,1])-1,len(Gspecies)])\n",
    "    for i in range(len(Gnmol[1,:])):\n",
    "        Gnmol[:,i] = o[Gspecies[i]][1:].astype(float)\n",
    "    \n",
    "    ### Calculating the instantaneous rates of profuction (i.e grad/sites)\n",
    "    TOF_GS = np.empty([len(o.iloc[:,1])-1,len(Gspecies)]) #initializing an array of instantaneous TOFs for gaseous species\n",
    "\n",
    "    for i in np.arange(len(Gspecies)):\n",
    "        grads = np.gradient(Gnmol[:,i],Gtime,edge_order=2)\n",
    "        TOF_GS[:,i] = grads/sites\n",
    "    \n",
    "    \n",
    "    #initializing TOF for gas species\n",
    "    STOF = np.empty([n_points,n_gas_species])\n",
    "    gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "    gs_names_colmn = []\n",
    "    \n",
    "    for i in np.arange(n_gas_species): #Collecting TOFs\n",
    "        STOF[:,i] = pd.Series(TOF_GS[:,i])\n",
    "        \n",
    "    for i in gs_names: #Collecting gas names\n",
    "        gs_names_colmn.append('R_'+i)\n",
    "    \n",
    "    Rates_p = pd.DataFrame(STOF,\n",
    "                    columns = gs_names_colmn)\n",
    "\n",
    "    init_covg = []\n",
    "    for i in np.arange(n_surf_species):    #A_O*_covg,     B_CO*_covg,     O2*_covg, *_covg\n",
    "        init_covg.append(Scoverages[0,i])\n",
    "        \n",
    "    init_coverages[c,:]= init_covg #Initial coverages\n",
    "    \n",
    "    KMC_time_Array[c,:]= Gtime #Time matrix\n",
    "     \n",
    "    Covg[c,:,:] = Scoverages #Coverage profile tensor\n",
    "    \n",
    "    Rates[c,:,:] = Rates_p\n",
    "    \n",
    "    c+=1\n",
    "    \n",
    "    os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is\n",
    "\n",
    "#https://stackoverflow.com/questions/49881570/python-dictionaries-appending-arrays-to-a-dictionary-for-a-specific-key\n",
    "data_KMC_dict_NON_LAT = {'init_covg': init_coverages, 'sim_time': KMC_time_Array, 'covg_prof': Covg, 'iRates': Rates}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec6491",
   "metadata": {},
   "source": [
    "## FOR LATERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45197d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Copying all the other input files into the different simulation folders\n",
    "# Extracting initial coverages\n",
    "#Remember: A='O*'; B='CO*'\n",
    "n = len(Sim_folder_names_lat)\n",
    "\n",
    "Covg = np.zeros((n,n_points,n_surf_species)) #CO*, O*, O2*, *\n",
    "Rates = np.zeros((n,n_points,n_gas_species)) #O2, CO, CO2\n",
    "KMC_time_Array = np.zeros((n,n_points))\n",
    "init_coverages = np.empty([n,n_surf_species])\n",
    "c = 0 #counter for number of simulation (folders)\n",
    "\n",
    "for s in Sim_folder_names_lat:\n",
    "    os.chdir(s)\n",
    "    file=open('specnum_output.txt','r').readlines() #Reading in the relevant file\n",
    "    b=[]\n",
    "    for i in np.arange(len(file)): \n",
    "        b.append(file[i].split())                   #Dividing the rows into columns\n",
    "    o = pd.DataFrame(data=b)                        #Final output\n",
    "\n",
    "#     print(o)\n",
    "    #Extracting Number of Sites from the general_output file:\n",
    "    inp=open('general_output.txt','r').readlines()\n",
    "    for i in np.arange(len(inp)): \n",
    "        if 'Total number of lattice sites:' in inp[i]:\n",
    "            val = i  #Line in text file where sentence is present\n",
    "\n",
    "    sites = int(inp[val][34:])\n",
    "    \n",
    "    #Finding number of surface species\n",
    "    headings = (o.iloc[0,:])\n",
    "    n_ss = sum('*' in h for h in headings) #Number of surface species\n",
    "    \n",
    "    #Finding number of gas species\n",
    "    n_gs = len(headings)-5-n_ss\n",
    "    \n",
    "    #Adding column to calculate number of empty sites\n",
    "    n_c=(len(o.iloc[0,:])) #number of current columns\n",
    "    o[n_c]=\" \"           #Creating new empty column \n",
    "    o.iloc[0,n_c]=\"*\"    #Labelling the new empty column \n",
    "\n",
    "    st = 0 #Initializing empty site coverage vector\n",
    "\n",
    "\n",
    "    for i in range(len(o.iloc[1:])):\n",
    "        if n_ss==0:\n",
    "            site = sites\n",
    "        else:\n",
    "            for j in range(n_ss):\n",
    "                st = st + float(o.iloc[i+1,5+j]) #Calculating no. of empty sites #Asuming empty sites are first to be reportes (i.e @5)\n",
    "            site = sites - st\n",
    "            st = 0\n",
    "        o.iloc[i+1,n_c] = site\n",
    "    \n",
    "    Sspecies = []\n",
    "    for i in range(n_ss):\n",
    "        Sspecies.append(5+i) \n",
    "    Sspecies.append(len(o.iloc[1,:])-1)#Including empty sites\n",
    "\n",
    "    #Calculating itme:\n",
    "    Gtime = o[2][1:].astype(float) \n",
    "    \n",
    "    #Calculating coverages:\n",
    "    Scoverages = np.empty([len(o.iloc[:,1])-1,len(Sspecies)])\n",
    "    for i in range(len(Scoverages[1,:])):\n",
    "        Scoverages[:,i] = o[Sspecies[i]][1:].astype(float)/sites\n",
    "        \n",
    "    Gspecies = []\n",
    "    for i in range(n_gs):\n",
    "        Gspecies.append(5+n_ss+i) \n",
    "        \n",
    "    #Extracting the number of gas species molecules:    \n",
    "    Gnmol = np.empty([len(o.iloc[:,1])-1,len(Gspecies)])\n",
    "    for i in range(len(Gnmol[1,:])):\n",
    "        Gnmol[:,i] = o[Gspecies[i]][1:].astype(float)\n",
    "    \n",
    "    ### Calculating the instantaneous rates of profuction (i.e grad/sites)\n",
    "    TOF_GS = np.empty([len(o.iloc[:,1])-1,len(Gspecies)]) #initializing an array of instantaneous TOFs for gaseous species\n",
    "\n",
    "    for i in np.arange(len(Gspecies)):\n",
    "        grads = np.gradient(Gnmol[:,i],Gtime,edge_order=2)\n",
    "        TOF_GS[:,i] = grads/sites\n",
    "    \n",
    "    \n",
    "    #initializing TOF for gas species\n",
    "    STOF = np.empty([n_points,n_gas_species])\n",
    "    gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "    gs_names_colmn = []\n",
    "    \n",
    "    for i in np.arange(n_gas_species): #Collecting TOFs\n",
    "        STOF[:,i] = pd.Series(TOF_GS[:,i])\n",
    "        \n",
    "    for i in gs_names: #Collecting gas names\n",
    "        gs_names_colmn.append('R_'+i)\n",
    "    \n",
    "    Rates_p = pd.DataFrame(STOF,\n",
    "                    columns = gs_names_colmn)\n",
    "\n",
    "    init_covg = []\n",
    "    for i in np.arange(n_surf_species):    #A_O*_covg,     B_CO*_covg,     O2*_covg, *_covg\n",
    "        init_covg.append(Scoverages[0,i])\n",
    "        \n",
    "    init_coverages[c,:]= init_covg #Initial coverages\n",
    "    \n",
    "    KMC_time_Array[c,:]= Gtime #Time matrix\n",
    "     \n",
    "    Covg[c,:,:] = Scoverages #Coverage profile tensor\n",
    "    \n",
    "    Rates[c,:,:] = Rates_p\n",
    "    \n",
    "    c+=1\n",
    "    \n",
    "    os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is\n",
    "\n",
    "#https://stackoverflow.com/questions/49881570/python-dictionaries-appending-arrays-to-a-dictionary-for-a-specific-key\n",
    "data_KMC_dict_LAT = {'init_covg': init_coverages, 'sim_time': KMC_time_Array, 'covg_prof': Covg, 'iRates': Rates}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94108ede",
   "metadata": {},
   "source": [
    "## Starting to Create ML dataset\n",
    "### x:n_features ; y = n_points ; z = n_simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f803a",
   "metadata": {},
   "source": [
    "<a id=\"2.4\"></a> \n",
    "## 2.D  Creating Input/Feature Tensor\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Creating Simulation file names input\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "Sim_names_tens_non = np.empty((n,n_points,1),dtype=np.dtype('U100'))\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(n_points):\n",
    "        Sim_names_tens_non[i,j,:] = Sim_folder_names_non[i]\n",
    "        \n",
    "Sim_names_tens_lat = np.empty((n,n_points,1),dtype=np.dtype('U100'))\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(n_points):\n",
    "        Sim_names_tens_lat[i,j,:] = Sim_folder_names_lat[i]\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "## Creating Init coverages tensor input\n",
    "ini_covg_tens_non = np.empty((n,n_points,n_surf_species),dtype=float)\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(n_points):\n",
    "        ini_covg_tens_non[i,j,:] = data_KMC_dict_NON_LAT['init_covg'][i,:]\n",
    "        \n",
    "## Creating Init coverages tensor input\n",
    "ini_covg_tens_lat = np.empty((n,n_points,n_surf_species),dtype=float)\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(n_points):\n",
    "        ini_covg_tens_lat[i,j,:] = data_KMC_dict_LAT['init_covg'][i,:]\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------\n",
    "## Creating time tensor input\n",
    "sim_time_tens_non = np.empty((n,n_points,1),dtype=float)\n",
    "for i in np.arange(n):\n",
    "    for z in np.arange(1):\n",
    "        sim_time_tens_non[i,:,z] = data_KMC_dict_NON_LAT['sim_time'][i,:]\n",
    "        \n",
    "## Creating time tensor input\n",
    "sim_time_tens_lat = np.empty((n,n_points,1),dtype=float)\n",
    "for i in np.arange(n):\n",
    "    for z in np.arange(1):\n",
    "        sim_time_tens_lat[i,:,z] = data_KMC_dict_LAT['sim_time'][i,:]\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49520af1",
   "metadata": {},
   "source": [
    "## Tenosr_To_Array Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tensor_To_Array(Sim_tens):\n",
    "    a = Sim_tens\n",
    "    m,n,r = a.shape\n",
    "    sim_arr = np.column_stack((np.repeat(np.arange(m),n),a.reshape(m*n,-1)))\n",
    "    return sim_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772afea3",
   "metadata": {},
   "source": [
    "## Creating Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a57f6",
   "metadata": {},
   "source": [
    "## DATAFRAME FOR NON LATERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_non = pd.DataFrame(Tensor_To_Array(Sim_names_tens_non),columns= ['Sim_ndex','Sim_names'])\n",
    "out_df_lat = pd.DataFrame(Tensor_To_Array(Sim_names_tens_lat),columns= ['Sim_ndex','Sim_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46997abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding initial coverages\n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df_non['Init_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(ini_covg_tens_non))[1+i]\n",
    "    \n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df_lat['Init_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(ini_covg_tens_lat))[1+i]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa5f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding time\n",
    "out_df_non['Time'] = pd.DataFrame(Tensor_To_Array(sim_time_tens_non))[1]\n",
    "out_df_lat['Time'] = pd.DataFrame(Tensor_To_Array(sim_time_tens_lat))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7764725",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding KMC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80651579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding coverage profiles of surface species\n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df_non['KMC_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(data_KMC_dict_NON_LAT['covg_prof']))[1+i]\n",
    "    \n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df_lat['KMC_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(data_KMC_dict_LAT['covg_prof']))[1+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ace6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding iRates profiles of gaseous species\n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df_non['KMC_iRates_'+spec] = pd.DataFrame(Tensor_To_Array(data_KMC_dict_NON_LAT['iRates']))[1+i]\n",
    "    \n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df_lat['KMC_iRates_'+spec] = pd.DataFrame(Tensor_To_Array(data_KMC_dict_LAT['iRates']))[1+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f84537",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replicating out_df_lat to create a datframe to containe MKM siumulation results accounting for coverage dependenc\n",
    "#\n",
    "#\n",
    "out_df_lat_cd = out_df_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256884dc",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.2\"></a> \n",
    "## 2.B  Generating MF-MKModel Data Dictionary\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from main import *\n",
    "MKM = MKModel('Atomic_sw.csv','Stoich_sw.csv','Param_sw.csv')\n",
    "MKM.set_rxnconditions(Pr=[(1.0e-4*0.1),(1.0e-4*1.0e-5), 0]) #From KMC #Make sure it matches 02 CO CO2\n",
    "MKM_init_coverages = np.empty([len(Sim_folder_names_non),n_surf_species])\n",
    "\n",
    "def MKModelling(*fit_params,Sim_folder_names=Sim_folder_names_non, data_KMC_dict = data_KMC_dict_NON_LAT):\n",
    "    n_points = 500 #From KMC simulation \n",
    "    n_gas_species = 3 #From KMC simulation\n",
    "    n_surf_species = 4 #From KMC simulation\n",
    "    MKM_Covg = np.zeros((n,n_points,n_surf_species)) # O*,CO*, O2*, * #Make sure KMC order of species matches MKM inputs\n",
    "    MKM_Rates = np.zeros((n,n_points,n_gas_species)) #O2, CO, CO2     #Make sure KMC order of species matches MKM inputs\n",
    "    time_MKM_Array = np.zeros((n,n_points))\n",
    "\n",
    "    MKM.set_limits_of_integration(Ti=data_KMC_dict['sim_time'][0][0],Tf=data_KMC_dict['sim_time'][-1][-1])\n",
    "    \n",
    "    MKM.k = np.array(fit_params)\n",
    "    \n",
    "    #Remember: A='O*'; B='CO*'\n",
    "    #Reading A and B initial coverages from the KMC simulation input coverage file names!\n",
    "    c = 0 #counter\n",
    "    for s in Sim_folder_names:\n",
    "        set_coverages = []\n",
    "        for i in np.arange(len(s)):\n",
    "            if i<(len(s)-2) and s[i].isdigit() and (s[i+1]).isdigit() and (s[i+2]).isdigit():\n",
    "                cov_triple = int(s[i:i+3])\n",
    "                set_coverages.append(cov_triple)\n",
    "\n",
    "            elif i<(len(s)-1) and s[i].isdigit() and (s[i+1]).isdigit()and not((s[i-1]).isdigit()):\n",
    "                cov_double = int(s[i:i+2])\n",
    "                set_coverages.append(cov_double)\n",
    "\n",
    "            elif s[i].isdigit() and not((s[i-1]).isdigit()) and not((s[i-2]).isdigit()):\n",
    "                cov_single = int(s[i])\n",
    "                set_coverages.append(cov_single)\n",
    "                                    #A_O*_covg,     B_CO*_covg,     O2*_covg,*_covg  #Note: Special case: Simulation naming switches from KMC and MKM order\n",
    "        init_covgs = [set_coverages[0]/100,set_coverages[1]/100,0,(100-sum(set_coverages))/100]\n",
    "        \n",
    "        MKM.set_initial_coverages(init=init_covgs)\n",
    "        MKM_init_coverages[c,:] = [float(i) for i in init_covgs]\n",
    "        \n",
    "        sola,solta = MKM.solve_coverage(Tf_eval=data_KMC_dict['sim_time'][0],plot=False)\n",
    "        time_MKM_Array[c,:]= solta #Time matrix\n",
    "        MKM_Covg[c,:,:] = sola #Coverage profile tensor\n",
    "\n",
    "        solb,soltb = MKM.solve_rate_production(Tf_eval=data_KMC_dict['sim_time'][0],plot=False)\n",
    "        MKM_Rates[c,:,:] = solb[:,0:n_gas_species] \n",
    "\n",
    "        c+=1 #counter\n",
    "    return {'init_covg': MKM_init_coverages, 'sim_time': time_MKM_Array, 'covg_prof': MKM_Covg, 'iRates': MKM_Rates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03575a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average\n",
    "initial_vals = np.array([8.30E+02,5.58E-02,7.77E+06,1.04E+06,1.36E+05,1.79E-07,1.14E+00,0.00E+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max rates\n",
    "# fit_params = np.array([8.30E+02,7.47E-02,7.77E+06,2.05E+06,2.67E+05,3.58E-07,1.35E+00,0.00E+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32892fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min rates\n",
    "# fit_params = np.array([8.30E+02,3.69E-02,7.77E+06,3.49E+04,5.30E+03,7.33E-11,9.35E-01,0.00E+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd7194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mix rates _1 fwdmax, rvsmin\n",
    "# fit_params = np.array([8.30E+02,3.69E-02,7.77E+06,3.49E+04,2.67E+05,7.33E-11,1.35E+00,0.00E+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mix rates _2 fwdmin, rvsmax\n",
    "# fit_params = np.array([8.30E+02,7.47E-02,7.77E+06,2.05E+06,5.30E+03,3.58E-07,9.35E-01,0.00E+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mix rates _3 fwdmin, rvsavg\n",
    "# fit_params = np.array([8.30E+02,5.58E-02,7.77E+06,1.04E+06,5.30E+03,1.79E-07,9.35E-01,0.00E+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0badab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mix rates _4 fwdavg, rvsmin\n",
    "# fit_params = np.array([8.30E+02,3.69E-02,7.77E+06,3.49E+04,1.36E+05,7.33E-11,1.14E+00,0.00E+00])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91efb6",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.3.1\"></a> \n",
    "## 2.B.1 Optimizing Rate Constant:\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627899e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Fitting rate constant function due to the feature = iRates\n",
    "def MKM_k_fitting(x,*fit_params,feature = 'iRates'):\n",
    "    data_MKM_dict  = MKModelling(*fit_params)    \n",
    "    return np.reshape(data_MKM_dict[feature],data_MKM_dict[feature].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_values = data_KMC_dict_NON_LAT['sim_time'] #Normalized Input Time variables (Independent Variable) (eg. KMC Time)\n",
    "y_values = np.reshape(data_KMC_dict_NON_LAT['iRates'],data_KMC_dict_NON_LAT['iRates'].size) #Normalized Input Dependent variable(s) (eg. KMC coverages)\n",
    "\n",
    "params, params_covariance = optimize.curve_fit(MKM_k_fitting, x_values, y_values\n",
    "                                            ,method = 'trf', bounds=(0,1e12), maxfev=3e3, xtol=1e-12, ftol=1e-12\n",
    "                                            ,p0=initial_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6899fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(data_KMC_dict_NON_LAT['iRates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MKM.ODE_Tolerances(Dplace=60,reltol=1e-9,abstol=1e-9)\n",
    "data_MKM_dict_NON_LAT  = MKModelling(*fit_params,Sim_folder_names_non,data_KMC_dict=data_KMC_dict_NON_LAT)\n",
    "data_MKM_dict_LAT  = MKModelling(*fit_params,Sim_folder_names_lat,data_KMC_dict=data_KMC_dict_LAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9545b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Calculating Coverage Dependent case of MKM to be used to compare lateral interactions\n",
    "# MKM.rate_const_correction='Forced_exp_CD'\n",
    "data_MKM_dict_LAT_CD = MKModelling(*fit_params,Sim_folder_names_lat,data_KMC_dict=data_KMC_dict_LAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#Calculating the root mean squared of the test set\n",
    "print('Root Mean Squared Error:\\n',sqrt(mean_squared_error(y_values, np.reshape(data_MKM_dict_NON_LAT['iRates'],data_KMC_dict_NON_LAT['iRates'].size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MKM.ODE_Tolerances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the KMC fitting attempt\n",
    "##Perfect Fits\n",
    "# params = np.array([5.60983514e+07, 6.26873886e-10, 2.09163588e+04, 8.74022929e+09, 1.03443448e+10, 2.75903622e-01, 1.03031697e+08, 5.00000000e+02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0732b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# MKM.ODE_Tolerances(Dplace=50,reltol=1e-5,abstol=1e-8)\n",
    "# data_MKM_dict = MKModelling(*params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495e66a",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.3.2\"></a> \n",
    "## Adding MKM to dataframe\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dccf20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding coverage profiles of surface species\n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df_non['MKM_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(data_MKM_dict_NON_LAT['covg_prof']))[1+i]\n",
    "    \n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df_lat['MKM_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(data_MKM_dict_LAT['covg_prof']))[1+i]    \n",
    "    \n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df_lat_cd['MKM_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(data_MKM_dict_LAT_CD['covg_prof']))[1+i]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding iRates profiles of gaseous species\n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df_non['MKM_iRates_'+spec] = pd.DataFrame(Tensor_To_Array(data_MKM_dict_NON_LAT['iRates']))[1+i]\n",
    "    \n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df_lat['MKM_iRates_'+spec] = pd.DataFrame(Tensor_To_Array(data_MKM_dict_LAT['iRates']))[1+i]    \n",
    "    \n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df_lat_cd['MKM_iRates_'+spec] = pd.DataFrame(Tensor_To_Array(data_MKM_dict_LAT_CD['iRates']))[1+i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04028f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac328b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b1d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_lat_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90880662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## RMSE Evaluation of Fit\n",
    "# # from math import sqrt\n",
    "# import numpy as np\n",
    "# # rmse_fit_covg = []\n",
    "# # rmse_fit_iRates = []\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# rmse_matrix = []\n",
    "# for i in np.arange(len(set(out_df['Sim_ndex']))):\n",
    "    \n",
    "#     df = out_df.loc[out_df['Sim_ndex'] == str(i)]\n",
    "    \n",
    "#     #calculating covg  ---------------------------------------------------------------------------------\n",
    "#     df = out_df.loc[out_df['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "#     kmc_dat_covg = df[[col for col in df if 'KMC_Covg' in col]] #Extracting KMC comp data \n",
    "#     mkm_dat_covg = df[[col for col in df if 'MKM_Covg' in col]] #Extracting MKM comp data \n",
    "    \n",
    "#     ls = kmc_dat_covg.columns.to_list()\n",
    "#     covg_nm = [string[3:] for string in ls] #surface_species names\n",
    "     \n",
    "#     rmse_covg = []\n",
    "#     for i in np.arange(len(covg_nm)):\n",
    "#         rmse_covg.append(sqrt(mean_squared_error(kmc_dat_covg['KMC'+covg_nm[i]], mkm_dat_covg['MKM'+covg_nm[i]])))\n",
    "        \n",
    "    \n",
    "#     #calculating irates ---------------------------------------------------------------------------------\n",
    "    \n",
    "#     kmc_dat_irates = df[[col for col in df if 'KMC_iRates' in col]] #Extracting KMC comp data \n",
    "#     mkm_dat_irates = df[[col for col in df if 'MKM_iRates' in col]] #Extracting MKM comp data \n",
    "    \n",
    "#     ls = kmc_dat_irates.columns.to_list()\n",
    "#     irates_nm = [string[3:] for string in ls] #gas_species names\n",
    "    \n",
    "#     rmse_irates = []\n",
    "#     for i in np.arange(len(irates_nm)):\n",
    "#         rmse_irates.append(sqrt(mean_squared_error(kmc_dat_irates['KMC'+irates_nm[i]], mkm_dat_irates['MKM'+irates_nm[i]])))\n",
    "        \n",
    "#     rmse_matrix.append(rmse_covg+rmse_irates)\n",
    "    \n",
    "#     rmse_names = covg_nm+irates_nm\n",
    "    \n",
    "# #Creating the RMSE Dataframe\n",
    "\n",
    "# RMSE_Dataframe = pd.DataFrame(list(set(out_df['Sim_names'])), columns = ['Sim_names'])\n",
    "\n",
    "# for i in np.arange(len(rmse_names)):\n",
    "#     spec = rmse_names[i]\n",
    "#     RMSE_Dataframe['RMSE'+spec] = pd.DataFrame(rmse_matrix).applymap(lambda x: round(x, 3))[i]\n",
    "\n",
    "# RMSE_Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcdfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ff550",
   "metadata": {},
   "source": [
    "# Visual Evaluation of Fitting Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92780626",
   "metadata": {},
   "source": [
    "## SET 1: NON LATERAL KMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee498d9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Part 1: Choose the feature of which you we will compare the k-opt values\n",
    "\n",
    "# Comp = 'iRates'\n",
    "Comp = 'Covg'\n",
    "\n",
    "colors = ['b','g','m','r','c','y','k'] \n",
    "\n",
    "# print('Comparison of KMC vs fitted-k MKM results for' + Comp)\n",
    "\n",
    "#Part 2: Plot comparison results for fitting analysis\n",
    "for i in np.arange(len(set(out_df_non['Sim_ndex']))): #For each simulation:\n",
    "        #Extracting KMC results: ------------------------------------------------\n",
    "        \n",
    "        df_non = out_df_non.loc[out_df_non['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        kmc_dat_non = df_non[[col for col in df_non if 'KMC_'+Comp in col]].to_numpy() #Extracting KMC comp data as array\n",
    "        \n",
    "        df_lat = out_df_lat.loc[out_df_lat['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        kmc_dat_lat = df_lat[[col for col in df_lat if 'KMC_'+Comp in col]].to_numpy() #Extracting KMC comp data as array\n",
    "        \n",
    "        Time = df_non['Time'].to_numpy()\n",
    "\n",
    "        #Plotting KMC result : ------------------------------------------------          \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        for i in np.arange(len(kmc_dat_non[0,:])):\n",
    "            ax.plot(Time, kmc_dat_non[:,i],colors[i]+'--')\n",
    "            \n",
    "        if Comp =='iRates':\n",
    "            leg_nd = (o.iloc[0,Gspecies].tolist())\n",
    "            ax.set_ylim([-0.2,0.2])\n",
    "        elif Comp == 'Covg':\n",
    "            leg_nd = (o.iloc[0,Sspecies].tolist())\n",
    "            \n",
    "        ax.set_xlabel('Time, t, [s]')\n",
    "        if Comp =='iRates':\n",
    "            ax.set_ylabel(r\"Rates of Production, $R_i$\")\n",
    "            ax.set_title('Rates of production versus Time_ for Simulation_'+ df_non['Sim_ndex'].iloc[i] +': _'+df_non['Sim_names'].iloc[0][:-4] +'| A:O* ; B:CO*')\n",
    "        elif Comp == 'Covg':\n",
    "            ax.set_ylabel(r\"Coverage, $\\theta_i, [ML]$\")\n",
    "            ax.set_title('Coverages versus Time_for Simulation_'+ df_non['Sim_ndex'].iloc[i] +': _'+df_non['Sim_names'].iloc[0][:-4] +'| A:O* ; B:CO*')\n",
    "        \n",
    "        \n",
    "        #Extracting MKM results: ------------------------------------------------\n",
    "        mkm_dat_non = df_non[[col for col in df_non if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        Time = df_non['Time'].to_numpy()\n",
    "            \n",
    "            \n",
    "        #Adding to the plot, MKM result : ------------------------------------------------     \n",
    "        for i in np.arange(len(mkm_dat_non[0,:])):\n",
    "            ax.plot(Time, mkm_dat_non[:,i],colors[i]+'-')\n",
    "        \n",
    "        #Plotting all the legends together\n",
    "        ax.legend([f\"{string}_KMC_NonLat\" for string in leg_nd]+[f\"{string}_MKM\" for string in leg_nd],fontsize=7, loc='best',facecolor='white', edgecolor ='black', framealpha=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2a641",
   "metadata": {},
   "source": [
    "## SET 2: LATERAL KMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50978096",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Part 1: Choose the feature of which you we will compare the k-opt values\n",
    "\n",
    "# Comp = 'iRates'\n",
    "Comp = 'Covg'\n",
    "\n",
    "print('Comparison of KMC vs fitted-k MKM results for' + Comp)\n",
    "\n",
    "#Part 2: Plot comparison results for fitting analysis\n",
    "for i in np.arange(len(set(out_df_non['Sim_ndex']))): #For each simulation:\n",
    "        #Extracting KMC results: ------------------------------------------------\n",
    "        df_non = out_df_non.loc[out_df_non['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        kmc_dat_non = df_non[[col for col in df_non if 'KMC_'+Comp in col]].to_numpy() #Extracting KMC comp data as array\n",
    "        \n",
    "        df_lat = out_df_lat.loc[out_df_lat['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        kmc_dat_lat = df_lat[[col for col in df_lat if 'KMC_'+Comp in col]].to_numpy() #Extracting KMC comp data as array\n",
    "        \n",
    "        df_lat_cd = out_df_lat_cd.loc[out_df_lat_cd['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        \n",
    "        Time = df_non['Time'].to_numpy()\n",
    "\n",
    "        #Plotting KMC result : ------------------------------------------------          \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        for i in np.arange(len(kmc_dat_non[0,:])):\n",
    "            ax.plot(Time, kmc_dat_lat[:,i],colors[i]+'--')\n",
    "                        \n",
    "        if Comp =='iRates':\n",
    "            leg_nd = (o.iloc[0,Gspecies].tolist())\n",
    "            ax.set_ylim([-0.2,0.2])\n",
    "        elif Comp == 'Covg':\n",
    "            leg_nd = (o.iloc[0,Sspecies].tolist())\n",
    "            \n",
    "        ax.set_xlabel('Time, t, [s]')\n",
    "        if Comp =='iRates':\n",
    "            ax.set_ylabel(r\"Rates of Production, $R_i$\")\n",
    "            ax.set_title('Rates of production versus Time_ for Simulation_'+ df_non['Sim_ndex'].iloc[i] +': _'+df_non['Sim_names'].iloc[0][:-4]+'| A:O* ; B:CO*')\n",
    "        elif Comp == 'Covg':\n",
    "            ax.set_ylabel(r\"Coverage, $\\theta_i, [ML]$\")\n",
    "            ax.set_title('Coverages versus Time_for Simulation_'+ df_non['Sim_ndex'].iloc[i] +': _'+df_non['Sim_names'].iloc[0][:-4] +'| A:O* ; B:CO*')\n",
    "        \n",
    "        \n",
    "        #Extracting MKM results: ------------------------------------------------\n",
    "        mkm_dat_non = df_non[[col for col in df_non if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        mkm_dat_lat_cd = df_lat_cd[[col for col in df_lat_cd if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        mkm_dat_lat = df_lat[[col for col in df_lat if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        Time = df_non['Time'].to_numpy()\n",
    "            \n",
    "            \n",
    "        #Adding to the plot, MKM result : ------------------------------------------------     \n",
    "#         for i in np.arange(len(mkm_dat_non[0,:])):\n",
    "#             ax.plot(Time, mkm_dat_non[:,i],'--')\n",
    "        for i in np.arange(len(mkm_dat_non[0,:])):\n",
    "            ax.plot(Time, mkm_dat_lat_cd[:,i],colors[i]+'-')\n",
    "#         for i in np.arange(len(mkm_dat_non[0,:])):\n",
    "#             ax.plot(Time, mkm_dat_lat[:,i],'^-')\n",
    "            \n",
    "        \n",
    "        #Plotting all the legends together\n",
    "        ax.legend([f\"{string}_KMC_Lat\" for string in leg_nd]+[f\"{string}_MKM\" for string in leg_nd],fontsize=7, loc='best',facecolor='white', edgecolor ='black', framealpha=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdff6dd",
   "metadata": {},
   "source": [
    "## NONLAT VS LAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41b1ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Part 1: Choose the feature of which you we will compare the k-opt values\n",
    "\n",
    "# Comp = 'iRates'\n",
    "Comp = 'Covg'\n",
    "\n",
    "print('Comparison of KMC vs fitted-k MKM results for' + Comp)\n",
    "\n",
    "#Part 2: Plot comparison results for fitting analysis\n",
    "for i in np.arange(len(set(out_df_non['Sim_ndex']))): #For each simulation:\n",
    "        #Extracting KMC results: ------------------------------------------------\n",
    "        df_non = out_df_non.loc[out_df_non['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        kmc_dat_non = df_non[[col for col in df_non if 'KMC_'+Comp in col]].to_numpy() #Extracting KMC comp data as array\n",
    "        \n",
    "        df_lat = out_df_lat.loc[out_df_lat['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        kmc_dat_lat = df_lat[[col for col in df_lat if 'KMC_'+Comp in col]].to_numpy() #Extracting KMC comp data as array\n",
    "        \n",
    "        df_lat_cd = out_df_lat_cd.loc[out_df_lat_cd['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        \n",
    "        Time = df_non['Time'].to_numpy()\n",
    "\n",
    "        #Plotting KMC result : ------------------------------------------------          \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        for i in np.arange(len(kmc_dat_non[0,:])):\n",
    "            ax.plot(Time, kmc_dat_non[:,i],colors[i]+'--')\n",
    "        for i in np.arange(len(kmc_dat_non[0,:])):\n",
    "            ax.plot(Time, kmc_dat_lat[:,i],colors[i]+'-')\n",
    "                        \n",
    "        if Comp =='iRates':\n",
    "            leg_nd = (o.iloc[0,Gspecies].tolist())\n",
    "            ax.set_ylim([-0.2,0.2])\n",
    "        elif Comp == 'Covg':\n",
    "            leg_nd = (o.iloc[0,Sspecies].tolist())\n",
    "            \n",
    "        ax.set_xlabel('Time, t, [s]')\n",
    "        if Comp =='iRates':\n",
    "            ax.set_ylabel(r\"Rates of Production, $R_i$\")\n",
    "            ax.set_title('Rates of production versus Time_ for Simulation_'+ df_non['Sim_ndex'].iloc[i] +': _'+df_non['Sim_names'].iloc[0][:-4]+'| A:O* ; B:CO*')\n",
    "        elif Comp == 'Covg':\n",
    "            ax.set_ylabel(r\"Coverage, $\\theta_i, [ML]$\")\n",
    "            ax.set_title('Coverages versus Time_for Simulation_'+ df_non['Sim_ndex'].iloc[i] +': _'+df_non['Sim_names'].iloc[0][:-4] +'| A:O* ; B:CO*')\n",
    "        \n",
    "        \n",
    "        #Extracting MKM results: ------------------------------------------------\n",
    "        mkm_dat_non = df_non[[col for col in df_non if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        mkm_dat_lat_cd = df_lat_cd[[col for col in df_lat_cd if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        mkm_dat_lat = df_lat[[col for col in df_lat if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        Time = df_non['Time'].to_numpy()\n",
    "            \n",
    "            \n",
    "#         #Adding to the plot, MKM result : ------------------------------------------------     \n",
    "#         for i in np.arange(len(mkm_dat_non[0,:])):\n",
    "#             ax.plot(Time, mkm_dat_non[:,i],'x-')\n",
    "#             ax.plot(Time, mkm_dat_lat[:,i],'c-')\n",
    "#             ax.plot(Time, mkm_dat_lat_cd[:,i],'c--')\n",
    "        \n",
    "        #Plotting all the legends together\n",
    "        ax.legend([f\"{string}_KMC_NonLat\" for string in leg_nd]+ [f\"{string}_KMC_Lat\" for string in leg_nd],fontsize=7, loc='best',facecolor='white', edgecolor ='black', framealpha=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcf6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7e49a19",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- ----------------------------------------------------------- -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1da96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a3718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a7c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446dee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086187a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
