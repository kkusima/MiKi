{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2bb29a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ab063-7637-456a-af07-c42971cbe082",
   "metadata": {},
   "source": [
    "# DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b5736b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '18047_With_PS.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m File_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18047_With_PS.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Extracting X2: DO (hr^-1)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m DO \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(File_name, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Extracting relevant Parameters\u001b[39;00m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(File_name, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ:W\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, engine\u001b[38;5;241m=\u001b[39mengine)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1497\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1498\u001b[0m     )\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1503\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1372\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '18047_With_PS.xlsx'"
     ]
    }
   ],
   "source": [
    "## Reading in the Data from excel file\n",
    "File_name = '18047_With_PS.xlsx'\n",
    "# Extracting X2: DO (hr^-1)\n",
    "DO = pd.read_excel(File_name, header=6, usecols='H') \n",
    "\n",
    "#Extracting relevant Parameters\n",
    "df = pd.read_excel(File_name, header=6, usecols='Q:W')\n",
    "df = df.dropna(how='all')\n",
    "df = pd.merge(df, DO, left_index=True, right_index=True) #Merging the expermental dataframe with DO but mathcing the indexes\n",
    "df = df.rename(columns={'DO': 'DO (1/hr)'}) #Adding the appropriate units\n",
    "\n",
    "# Extracting X1: Phosphoric acid (PA)\n",
    "PA = pd.read_excel(File_name, header=6, usecols='P') #Experimental X1\n",
    "udata = np.zeros(len(PA))\n",
    "for i in np.arange(len(PA)-1):\n",
    "    val_j = PA.iloc[i]\n",
    "    val_j_1 = PA.iloc[i+1]\n",
    "    \n",
    "    udata[i] = (val_j_1 - val_j)*(453.592*30)\n",
    "PA['Converted -> g/L'] = udata \n",
    "df = pd.merge(df, PA['Converted -> g/L'], left_index=True, right_index=True) #Merging the expermental dataframe with PA but mathcing the indexes\n",
    "df = df.rename(columns={'Converted -> g/L': 'PA (g/L)'}) #Adding the appropriate units\n",
    "\n",
    "# Extracting Fin: Phosphoric acid (PA)\n",
    "Fin = pd.read_excel(File_name, header=6, usecols='F').apply(lambda x: x*(3.78541/6.586)) #Convert to L/hr #Conversion factor used, SOURCE: UNKNOWN\n",
    "df = pd.merge(df, Fin, left_index=True, right_index=True) #Merging the expermental dataframe with DO but mathcing the indexes\n",
    "df = df.rename(columns={'Ethanol Flow Rate (Lbs/Hr)': 'Ethanol Flow Rate (L/Hr)'})\n",
    "\n",
    "# Extracting Temperature: Kelvin\n",
    "Temp = pd.read_excel(File_name, header=6, usecols='C').apply(lambda x: ((x - 32)* 5/9) + 273.15) #Convert to K\n",
    "df = pd.merge(df, Temp, left_index=True, right_index=True) #Merging the expermental dataframe with DO but mathcing the indexes\n",
    "df = df.rename(columns={'Temperature in the Fermenter (F)': 'Temperature in the Fermenter (K)'})\n",
    "\n",
    "#Note:\n",
    "# X2: DO (hr^-1)\n",
    "# S1: Glucose\n",
    "# S2: Ethanol\n",
    "# X1: Phosphoric acid (PA)\n",
    "# S2 flow rate: Ethanol flow rate\n",
    "# Temperature in K\n",
    "# I: Intermediate\n",
    "\n",
    "#(From investigating:)\n",
    "# Cell Dry Weight (g/L)-> Biomass\n",
    "# Acetic Acid Concentration (g/L) -> Intermediate ##\n",
    "\n",
    "#Correcting the datframes Units accordingly:\n",
    "df['Cell Dry Weight %'] = df['Cell Dry Weight %'].apply(lambda x: x*(20000*0.001))\n",
    "df = df.rename(columns={'Cell Dry Weight %': 'Cell Dry Weight g/L'})\n",
    "\n",
    "df['Ethanol Concentration (ppm)'] = df['Ethanol Concentration (ppm)'].apply(lambda x: x*(0.001))\n",
    "df = df.rename(columns={'Ethanol Concentration (ppm)': 'Ethanol Concentration (g/L)'})\n",
    "\n",
    "df['Broth Volume (gal)'] = df['Broth Volume (gal)'].apply(lambda x: x*3.78541)\n",
    "df = df.rename(columns={'Broth Volume (gal)': 'Broth Volume (L)'})\n",
    "\n",
    "#I.E\n",
    "# data_Biomass = data_cellBiomass.*(20000*0.001); #% to ppm to g/L\n",
    "# data_Ethanol = data_ppmEthanol.*(0.001); #ppm to g/L\n",
    "# data_Volume = data_Volume_old*3.78541;  #Gallon to litre\n",
    "\n",
    "df = df[df['Approximate Hour of Fermentation'] < 218.0] # Removing the last line (Gap is not 4 hours)\n",
    "#Separating data into phase 1 and phase 2\n",
    "OG_phase_1 = df[df['Approximate Hour of Fermentation'] <= 24.0]\n",
    "OG_phase_2 = df[df['Approximate Hour of Fermentation'] > 24.0]\n",
    "\n",
    "#Extracting relevant variables\n",
    "exp_phase_1 = pd.DataFrame()\n",
    "exp_phase_1['Time [hr]'] = OG_phase_1['Approximate Hour of Fermentation']\n",
    "exp_phase_1['S1 [g/L]'] = OG_phase_1['Glucose Concentration (g/L)']\n",
    "exp_phase_1['B [g/L]'] = OG_phase_1['Cell Dry Weight g/L']\n",
    "exp_phase_1['X2 [1/hr]'] = OG_phase_1['DO (1/hr)']\n",
    "\n",
    "exp_phase_2 = pd.DataFrame()\n",
    "exp_phase_2['Time [hr]'] = OG_phase_2['Approximate Hour of Fermentation']\n",
    "exp_phase_2['S1 [g/L]'] = OG_phase_2['Glucose Concentration (g/L)']\n",
    "exp_phase_2['S2 [g/L]'] = OG_phase_2['Ethanol Concentration (g/L)']\n",
    "exp_phase_2['I [g/L]'] = OG_phase_2['Acetic Acid Concentration (g/L)']\n",
    "exp_phase_2['P [g/L]'] = OG_phase_2['Q10 Concentration (g/L)']\n",
    "exp_phase_2['B [g/L]'] = OG_phase_2['Cell Dry Weight g/L']\n",
    "exp_phase_2['X2 [1/hr]'] = OG_phase_2['DO (1/hr)']\n",
    "exp_phase_2['X1 [g/L]'] = OG_phase_2['PA (g/L)']\n",
    "exp_phase_2['Fin [L/hr]'] = OG_phase_2['Ethanol Flow Rate (L/Hr)']\n",
    "exp_phase_2['T [K]'] = OG_phase_2['Temperature in the Fermenter (K)']\n",
    "exp_phase_2['V [L]'] = OG_phase_2['Broth Volume (L)']\n",
    "\n",
    "exp_phase_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70019585-9632-4101-ac30-7ac1d7d2c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['PA (g/L)'].to_csv('X1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f0db949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_NaN_rows(df, num_rows):\n",
    "    r,c = np.shape(df)\n",
    "    r = r-1 #Removing header\n",
    "    rep_rws = int(num_rows/r) #Rows to repeat\n",
    "    total_r = num_rows + r\n",
    "    NaN_array = np.empty((total_r,c))\n",
    "    NaN_array[:] = np.NaN\n",
    "    \n",
    "    NaN_array[0,:] = df.iloc[0,:].values.flatten().tolist()\n",
    "    df = df.iloc[1:,:]\n",
    "    for i in np.arange(r-1):\n",
    "        NaN_array[rep_rws+(i*rep_rws),:] = df.iloc[i,:].values.flatten().tolist()\n",
    "\n",
    "    NaN_array[-1,:] = df.iloc[-1,:].values.flatten().tolist()\n",
    "\n",
    "    New_df = pd.DataFrame(NaN_array)\n",
    "    New_df.columns = df.columns\n",
    "    return New_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522ac6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    val = MinMaxScaler().fit_transform(np.array(data).reshape(-1, 1))\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be2f78ce-b303-4777-8ca9-0bdc2126dba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interpolate(x):\n",
    "    if x.notnull().sum().all() > 1:\n",
    "        return x.interpolate(method=\"cubic\",limit_direction='forward').ffill().bfill()\n",
    "    else:\n",
    "        return x.ffill().bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8d57d",
   "metadata": {},
   "source": [
    "# PHASE 1 Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3088f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time [hr]</th>\n",
       "      <th>S1 [g/L]</th>\n",
       "      <th>B [g/L]</th>\n",
       "      <th>X2 [1/hr]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>4.0</td>\n",
       "      <td>72.745680</td>\n",
       "      <td>9.30</td>\n",
       "      <td>9.188982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>8.0</td>\n",
       "      <td>61.344598</td>\n",
       "      <td>15.86</td>\n",
       "      <td>7.506001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>12.0</td>\n",
       "      <td>44.464385</td>\n",
       "      <td>26.14</td>\n",
       "      <td>5.929868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>16.0</td>\n",
       "      <td>29.430083</td>\n",
       "      <td>41.34</td>\n",
       "      <td>4.019798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.831286</td>\n",
       "      <td>65.08</td>\n",
       "      <td>6.101342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time [hr]   S1 [g/L]  B [g/L]  X2 [1/hr]\n",
       "111        4.0  72.745680     9.30   9.188982\n",
       "240        8.0  61.344598    15.86   7.506001\n",
       "356       12.0  44.464385    26.14   5.929868\n",
       "472       16.0  29.430083    41.34   4.019798\n",
       "591       20.0   5.831286    65.08   6.101342"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_phase_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817db960",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 50 #Number of NEW rows\n",
    "exp_phase_1_extended = add_NaN_rows(exp_phase_1,num_rows)\n",
    "exp_phase_1_extended = exp_phase_1_extended.interpolate(method=\"cubic\",limit_direction='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb492883-3d38-4a35-9f97-4cff0abd390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the experimental Growth Rate (mu) \n",
    "udata = np.zeros(len(exp_phase_1_extended['B [g/L]']))\n",
    "udata[0] = 1.0\n",
    "for i in np.arange(len(exp_phase_1_extended['B [g/L]'])-1):\n",
    "    B_j = exp_phase_1_extended['B [g/L]'].iloc[i]\n",
    "    B_j_1 = exp_phase_1_extended['B [g/L]'].iloc[i+1]\n",
    "    time_j = exp_phase_1_extended['Time [hr]'].iloc[i]\n",
    "    time_j_1 = exp_phase_1_extended['Time [hr]'].iloc[i+1]\n",
    "    \n",
    "    udata[i+1] = ((B_j_1-B_j)/(time_j_1-time_j))/((B_j+B_j_1)/2)\n",
    "\n",
    "exp_phase_1_extended['Growth_rate, mu, [1/hr]'] = udata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8474e",
   "metadata": {},
   "source": [
    "# PHASE 2 Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "7779329a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_phase_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[677], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exp_phase_2\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp_phase_2' is not defined"
     ]
    }
   ],
   "source": [
    "exp_phase_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022042b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 50 #Number of NEW rows\n",
    "exp_phase_2_extended = exp_phase_2 #add_NaN_rows(exp_phase_2,num_rows)\n",
    "exp_phase_2_extended = exp_phase_2_extended.interpolate(method=\"piecewise_polynomial\",limit_direction='forward').ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62aa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the experimental Growth Rate (mu) \n",
    "udata = np.zeros(len(exp_phase_2_extended['B [g/L]']))\n",
    "udata[0] = 1.0\n",
    "for i in np.arange(len(exp_phase_2_extended['B [g/L]'])-1):\n",
    "    B_j = exp_phase_2_extended['B [g/L]'].iloc[i]\n",
    "    B_j_1 = exp_phase_2_extended['B [g/L]'].iloc[i+1]\n",
    "    time_j = exp_phase_2_extended['Time [hr]'].iloc[i]\n",
    "    time_j_1 = exp_phase_2_extended['Time [hr]'].iloc[i+1]\n",
    "    \n",
    "    udata[i+1] = ((B_j_1-B_j)/(time_j_1-time_j))/((B_j+B_j_1)/2)\n",
    "\n",
    "exp_phase_2_extended['Growth_rate, mu, [1/hr]'] = udata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a7911",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bb9afd0-b5f5-4bcc-b3f4-e23bf0636b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Things to Keep Note of:\n",
    "#-> Initial conditions when solving the ODES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b24c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "# X2: DO\n",
    "# S1: Glucose\n",
    "# S2: Ethanol\n",
    "# X1: Phosphoric acid (PS)\n",
    "# S2 flow rate: Ethanol flow rate\n",
    "# Temperature in K\n",
    "# I: Intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "baa9b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinetic_Model:\n",
    "    def __init__(self, Growth_Parameters = [0.808,2.44e2,0.377,1.84e2,0.954,63.7,5.08e2,9.99e2,4.91e2,1.01e2,4.95e2,5.13e2,6.49e-4],\\\n",
    "                Phase_1_Parameters = [0.903,0.117,0.223],\\\n",
    "                Phase_2_Parameters = [0.321,0.459,0.012,0.108,0.108,0.036,0.173,0.04,0.156,0.000134,24.8,24.8,0.498,9.99e-05,1.8e-07,5.13,16.6,1.0] ):\n",
    "        ######Growth Rate Parameters\n",
    "        self.mu_max_S1 = Growth_Parameters[0]    #hr^-1\n",
    "        self.K_S_S1 = Growth_Parameters[1]      #g Substrate 1 L^-1\n",
    "        self.mu_max_S2 = Growth_Parameters[2]    #hr^−1\n",
    "        self.K_S_S2 = Growth_Parameters[3]      #g Substrate 2 L^−1\n",
    "        self.mu_max_I = Growth_Parameters[4]     #hr^−1\n",
    "        self.K_S_I = Growth_Parameters[5]        #g Intermediate L^−1\n",
    "        self.a_S1_S2 = Growth_Parameters[6]     #-\n",
    "        self.a_S1_I = Growth_Parameters[7]      #-\n",
    "        self.a_S2_S1 = Growth_Parameters[8]     #-\n",
    "        self.a_S2_I = Growth_Parameters[9]      #-\n",
    "        self.a_I_S1 = Growth_Parameters[10]      #-\n",
    "        self.a_I_S2 = Growth_Parameters[11]      #-\n",
    "        self.K_X2 = Growth_Parameters[12]       #hr^-1\n",
    "        \n",
    "        self.Growth_Parameters = Growth_Parameters\n",
    "\n",
    "        ######Phase 1 Parameters\n",
    "        self.Y_B_S1_Ph1 = Phase_1_Parameters[0]       #g Cell/g Substrate 1\n",
    "        self.kL_a_Ph1 = Phase_1_Parameters[1]         #hr^-1\n",
    "        self.q_X2_Ph1 = Phase_1_Parameters[2]         #-\n",
    "        \n",
    "        self.Phase_1_Parameters = Phase_1_Parameters\n",
    "        \n",
    "        ######Phase 2 Parameters\n",
    "        self.Y_B_S1_Ph2 = Phase_2_Parameters[0]   #g Cell/g Substrate 1\n",
    "        self.Y_B_S2 = Phase_2_Parameters[1]       #g Cell/g Substrate 2\n",
    "        self.Y_B_I = Phase_2_Parameters[2]        #g Cell/g Intermediate\n",
    "        self.c1 = Phase_2_Parameters[3]           #g Substrate 1/g Cell \n",
    "        self.c2 = Phase_2_Parameters[4]           #g Substrate 2/g Cell\n",
    "        self.c3 = Phase_2_Parameters[5]           #g Intermediate/g Cell\n",
    "        self.alpha_1 = Phase_2_Parameters[6]      #g Product/g Substrate 1\n",
    "        self.alpha_2 = Phase_2_Parameters[7]      #g Product/g Substrate 2\n",
    "        self.alpha_3 = Phase_2_Parameters[8]      #g Product/g Intermediate\n",
    "        self.Beta = Phase_2_Parameters[9]         #g Product/g Cell hr\n",
    "        self.Ea_1 = Phase_2_Parameters[10]        #J/mol\n",
    "        self.Ea_2 = Phase_2_Parameters[11]        #J/mol\n",
    "        self.Ea_3 = Phase_2_Parameters[12]        #J/mol\n",
    "        self.p_1 = Phase_2_Parameters[13]         #hr^-1\n",
    "        self.p_2 = Phase_2_Parameters[14]         #hr^-1\n",
    "        self.kL_a_Ph2 = Phase_2_Parameters[15]    #hr^-1\n",
    "        self.q_X2_Ph2 = Phase_2_Parameters[16]    #-\n",
    "        self.mp1 = Phase_2_Parameters[17]         #-\n",
    "        \n",
    "        self.Phase_2_Parameters = [self.Y_B_S1_Ph2,self.Y_B_S2,self.Y_B_I,self.c1,self.c2,self.c3,\n",
    "                                    self.alpha_1,self.alpha_2,self.alpha_3,self.Beta,self.Ea_1,self.Ea_2,self.Ea_3,\n",
    "                                     self.p_1,self.p_2,self.kL_a_Ph2,self.q_X2_Ph2,self.mp1]\n",
    "        \n",
    "        self.R = 8.314            #Gas Constant J⋅mol^−1⋅K^−1.\n",
    "        \n",
    "        #Flow parameter\n",
    "        self.S2_initial = 740 #(questionable)g/L  #SOURCE: UNKNOWN\n",
    "        \n",
    "    def Phase_1(self,t,u):\n",
    "        S1 = u[0]                #g/L\n",
    "        B = u[1]                 #g Biomass / L\n",
    "        \n",
    "        self.mu_s1 = (self.mu_max_S1*S1) / (self.K_S_S1 + S1)\n",
    "        \n",
    "        dS1_dt = (-self.mu_s1 * B) / self.Y_B_S1_Ph1\n",
    "        dB_dt = self.mu_s1 * B \n",
    "        \n",
    "        return [dS1_dt, dB_dt] \n",
    "    \n",
    "    def Phase_1_with_X(self,t,u):\n",
    "        S1 = u[0]                #g/L\n",
    "        B = u[1]                 #g Biomass / L\n",
    "        X2 = u[2]                #hr^-1\n",
    "        X2_max =  np.max(DO.iloc[:].values[~np.isnan(DO.iloc[:].values)])  #Max DO value from raw data ~10.23 \n",
    "        \n",
    "        self.mu_s1_ph1_x = ( (self.mu_max_S1*S1) / (self.K_S_S1 + S1) ) * (X2 / (self.K_X2 + X2) )\n",
    "        \n",
    "        dS1_dt = (-self.mu_s1_ph1_x * B) / self.Y_B_S1_Ph1\n",
    "        dB_dt = self.mu_s1_ph1_x * B\n",
    "        dX2_dt = ( (self.kL_a_Ph1* (X2_max - X2) ) - (self.q_X2_Ph1 * B * self.mu_s1_ph1_x) ) \n",
    "         \n",
    "        return [dS1_dt, dB_dt, dX2_dt]\n",
    "    \n",
    "    def F_in_func(self,t):\n",
    "        return exp_phase_2_extended.loc[np.isclose(exp_phase_2_extended['Time [hr]'], float(t))]['Fin [L/hr]'].to_numpy()[0]\n",
    "    \n",
    "    def Temp_func(self,t):\n",
    "        return exp_phase_2_extended.loc[np.isclose(exp_phase_2_extended['Time [hr]'], float(t))]['T [K]'].to_numpy()[0]\n",
    "    \n",
    "    def Phase_2(self,t,u):\n",
    "        S1 = u[0]                #g/L\n",
    "        S2 = u[1]                #g/L\n",
    "        I = u[2]                 #g/L\n",
    "        B = u[3]                 #g Biomass / L\n",
    "        P = u[4]                 #g Product / L\n",
    "        V = u[5]                 #L\n",
    "\n",
    "        self.mu_s1 = ( (self.mu_max_S1*S1)/(self.K_S_S1 + S1 + (self.a_S1_S2*S2) + (self.a_S1_I * I)) )\n",
    "        self.mu_s2 = ( (self.mu_max_S2*S2)/(self.K_S_S2 + S2 + (self.a_S2_S1*S1) + (self.a_S2_I * I)) )\n",
    "        self.mu_I = ( (self.mu_max_I*I)/(self.K_S_I + I + (self.a_I_S1*S1) + (self.a_I_S2*S2)) )\n",
    "        self.mu = self.mu_s1 + self.mu_s2 + self.mu_I\n",
    "        \n",
    "        #Extracting time points to be used in equations\n",
    "        Time_list = exp_phase_2_extended['Time [hr]'].to_numpy() # List of time points to be used to obtain and get corresponding X1 values\n",
    "        #Rounding down the number deviations from the ODE solving process\n",
    "        index = np.argmin(np.abs(Time_list - t))\n",
    "        t = Time_list[index]\n",
    "        \n",
    "        #Kinetic coefficient\n",
    "        T = self.Temp_func(t)                #Kelvin \n",
    "        self.k1 = self.c1 * np.exp( (-self.Ea_1)/ (self.R * T)) #g Substrate 1/g Cell \n",
    "        self.k2 = self.c2 * np.exp( (-self.Ea_2)/ (self.R * T)) #g Substrate 2/g Cell \n",
    "        self.k3 = self.c3 * np.exp( (-self.Ea_3)/ (self.R * T)) #g Intermediate/g Cell \n",
    "        \n",
    "        F_in = self.F_in_func(t)\n",
    "        dB_dt = (self.mu * B) - (self.mp1 * (F_in/V) * B)\n",
    "        dS1_dt = -((self.mu_s1*B)/(self.Y_B_S1_Ph2)) - (F_in/V)*S1\n",
    "        dS2_dt = self.k1*self.mu_s1*B - ((self.mu_s2*B)/(self.Y_B_S2)) - ((F_in/V)*(S2 - self.S2_initial))\n",
    "        dI_dt = ((self.k2*self.mu_s1)+(self.k3*self.mu_s2))*B - ((self.mu_I*B)/(self.Y_B_I)) - ((F_in/V)*I)\n",
    "        dP_dt = ((self.alpha_1*self.mu_s1)+(self.alpha_2*self.mu_s2)+(self.alpha_3*self.mu_I))*B +\\\n",
    "                    (self.Beta*B) - ((F_in/V)*P)\n",
    "        dV_dt = F_in\n",
    "            \n",
    "        return [dS1_dt,dS2_dt,dI_dt,dB_dt,dP_dt,dV_dt]\n",
    "    \n",
    "    def X1_func(self,t):\n",
    "        return exp_phase_2_extended.loc[np.isclose(exp_phase_2_extended['Time [hr]'], float(t))]['X1 [g/L]'].to_numpy()[0]\n",
    "        \n",
    "    def Phase_2_with_X(self,t,u):\n",
    "        S1 = u[0]                #g/L\n",
    "        S2 = u[1]                #g/L\n",
    "        I = u[2]                 #g/L\n",
    "        B = u[3]                 #g Biomass / L\n",
    "        P = u[4]                 #g Product / L\n",
    "        V = u[5]                 #L\n",
    "        X2 = u[6]                #1/hr\n",
    "        X2_max = 6.88 #################### #Max DO value from phase 2 raw data SOURCE: Questionable\n",
    "\n",
    "        #Init: S1 | S2 | I | B | P | V | X2\n",
    "        \n",
    "        self.mu_s1 = ( (self.mu_max_S1*S1)/(self.K_S_S1 + S1 + (self.a_S1_S2*S2) + (self.a_S1_I * I)) )\n",
    "        self.mu_s2 = ( (self.mu_max_S2*S2)/(self.K_S_S2 + S2 + (self.a_S2_S1*S1) + (self.a_S2_I * I)) )\n",
    "        self.mu_I = ( (self.mu_max_I*I)/(self.K_S_I + I + (self.a_I_S1*S1) + (self.a_I_S2*S2)) )\n",
    "        self.mu = (self.mu_s1 + self.mu_s2 + self.mu_I) * (X2 / (self.K_X2 + X2) )\n",
    "        \n",
    "        #Extracting time points to be used in equations\n",
    "        Time_list = exp_phase_2_extended['Time [hr]'].to_numpy() # List of time points to be used to obtain and get corresponding X1 values\n",
    "        #Rounding down the number deviations from the ODE solving process\n",
    "        index = np.argmin(np.abs(Time_list - t))\n",
    "        t = Time_list[index]\n",
    "\n",
    "        #Kinetic coefficient\n",
    "        T = self.Temp_func(t)                #Kelvin \n",
    "        self.k1 = self.c1 * np.exp( (-self.Ea_1)/ (self.R * T)) #g Substrate 1/g Cell \n",
    "        self.k2 = self.c2 * np.exp( (-self.Ea_2)/ (self.R * T)) #g Substrate 2/g Cell \n",
    "        self.k3 = self.c3 * np.exp( (-self.Ea_3)/ (self.R * T)) #g Intermediate/g Cell    \n",
    "        \n",
    "        X1 = self.X1_func(t) \n",
    "        F_in = self.F_in_func(t)\n",
    "        dB_dt = (self.mu * B) - (self.mp1 * (F_in/V) * B)\n",
    "        dS1_dt = -((self.mu_s1*B)/(self.Y_B_S1_Ph2)) - (F_in/V)*S1\n",
    "        dS2_dt = self.k1*self.mu_s1*B - ((self.mu_s2*B)/(self.Y_B_S2)) - ((F_in/V)*(S2 - self.S2_initial)) - (self.p_1*X1)\n",
    "        dI_dt = ((self.k2*self.mu_s1)+(self.k3*self.mu_s2))*B - ((self.mu_I*B)/(self.Y_B_I)) - ((F_in/V)*I)\n",
    "        dP_dt = ((self.alpha_1*self.mu_s1)+(self.alpha_2*self.mu_s2)+(self.alpha_3*self.mu_I))*B +\\\n",
    "                    (self.Beta*B) - ((F_in/V)*P) + (self.p_2*X1)\n",
    "        dV_dt = F_in\n",
    "        dX2_dt = ( (self.kL_a_Ph2* (X2_max - X2) ) - (self.q_X2_Ph2 * B * self.mu) )\n",
    "        \n",
    "        return [dS1_dt,dS2_dt,dI_dt,dB_dt,dP_dt,dV_dt,dX2_dt]\n",
    "        \n",
    "    def solve_phase_1(self,init,Time,Teval = None):\n",
    "        t_span = (Time[0], Time[-1])\n",
    "        solve = solve_ivp(self.Phase_1,t_span,init,method='BDF',t_eval=Teval,rtol=1e-8, atol=1e-8)\n",
    "        sol = np.transpose(solve.y)\n",
    "        solt = np.transpose(solve.t)\n",
    "        return sol,solt\n",
    "    \n",
    "    def solve_phase_1_with_X(self,init,Time,Teval = None):\n",
    "        t_span = (Time[0], Time[-1])\n",
    "        solve = solve_ivp(self.Phase_1_with_X,t_span,init,method='BDF',t_eval=Teval,rtol=1e-8, atol=1e-8)\n",
    "        sol = np.transpose(solve.y)\n",
    "        solt = np.transpose(solve.t)\n",
    "        return sol,solt\n",
    "    \n",
    "    def solve_phase_2(self,init,Time,Teval = None):\n",
    "        t_span = (Time[0], Time[-1])\n",
    "        solve = solve_ivp(self.Phase_2,t_span,init,method='BDF',t_eval=Teval,rtol=1e-8, atol=1e-8)\n",
    "        sol = np.transpose(solve.y)\n",
    "        solt = np.transpose(solve.t)\n",
    "        return sol,solt\n",
    "    \n",
    "    def solve_phase_2_with_X(self,init,Time,Teval = None):\n",
    "        t_span = (Time[0], Time[-1])\n",
    "        solve = solve_ivp(self.Phase_2_with_X,t_span,init,method='BDF',t_eval=Teval,rtol=1e-8, atol=1e-8)\n",
    "        sol = np.transpose(solve.y)\n",
    "        solt = np.transpose(solve.t)\n",
    "        return sol,solt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68cef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947976ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c78c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009092b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9ea94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918068e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b524dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03165e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89f227fc-6124-4891-851d-55442092139f",
   "metadata": {},
   "source": [
    "# Hybrid Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "d8eb7f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input Layer Neurons:  9\n",
      "Number of Output Layer Neurons:  3 \n",
      "\n",
      "Total number of data points used:  48\n",
      "-----\n",
      "Number of Hidden Layers:  3\n",
      "Number of Neurons per Hidden Layer:  5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize(data):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    val = MinMaxScaler().fit_transform(np.array(data).reshape(-1, 1))\n",
    "    return val\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, no_hidden_layers, no_neurons_per_hidden_layer , output_size , no_data_points):\n",
    "        self.input_size = input_size #aka features\n",
    "        self.no_hidden_layers = no_hidden_layers\n",
    "        self.no_neurons_per_hidden_layer = no_neurons_per_hidden_layer\n",
    "        self.output_size = output_size\n",
    "        self.no_data_points = no_data_points\n",
    "        \n",
    "        print('Number of Input Layer Neurons: ', input_size)\n",
    "        print('Number of Output Layer Neurons: ', output_size,'\\n')\n",
    "        \n",
    "        print('Total number of data points used: ', no_data_points)\n",
    "        print('-----')\n",
    "        print('Number of Hidden Layers: ', no_hidden_layers)\n",
    "        print('Number of Neurons per Hidden Layer: ',no_neurons_per_hidden_layer)\n",
    "        \n",
    "        # Initializing weights and biases ---------------------------------------------\n",
    "        self.Weights_input = np.random.randn(self.input_size, self.no_neurons_per_hidden_layer)\n",
    "        self.Weights_hidden = np.random.randn(self.no_neurons_per_hidden_layer, self.no_neurons_per_hidden_layer, self.no_hidden_layers)\n",
    "        self.Weights_output = np.random.randn(self.no_neurons_per_hidden_layer, self.output_size)\n",
    "        \n",
    "        self.Biases_hidden = np.zeros((self.no_neurons_per_hidden_layer, self.no_hidden_layers))\n",
    "        self.Biases_output = np.zeros((1, self.output_size))\n",
    "        \n",
    "        # To carry the cummulative_input used in Jacobian\n",
    "#         self.cummulative_input = []\n",
    "        \n",
    "    def activation(self, x, activation_function):\n",
    "        if activation_function == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        if activation_function == 'ReLU':\n",
    "            return np.maximum(0,x)\n",
    "        if activation_function == 'tanh':\n",
    "            return np.tanh(x)\n",
    "\n",
    "    def activation_derivative(self, x, activation_function = 'sigmoid'):\n",
    "        if activation_function == 'sigmoid':\n",
    "            sigmoid_x = 1 / (1 + np.exp(-x))\n",
    "            return sigmoid_x * (1 - sigmoid_x)\n",
    "        if activation_function == 'ReLU':\n",
    "            return np.where(x > 0, 1, 0)\n",
    "        if activation_function == 'tanh':\n",
    "            return 1 - np.tanh(x)**2\n",
    "\n",
    "    def forward_pass(self, inputs, activation_function):\n",
    "        cummulative_input = [] #initializing the cummulative input (Input entering each layer) Starting from the 1st (hidden) layer\n",
    "        # From Input to Hidden Layer ---------------------------------------------\n",
    "        input_data = np.dot(inputs, self.Weights_input) \n",
    "        hidden_data = self.activation(input_data, activation_function)\n",
    "        cummulative_input.append(hidden_data)\n",
    "        \n",
    "        # Iterating through each Hidden Layer  ---------------------------------------------\n",
    "        for i in range(self.no_hidden_layers):\n",
    "            # Computing the pre-activation (weighted sum) for the current layer\n",
    "            pre_activation = np.dot(hidden_data, self.Weights_hidden[:,:,i]) + self.Biases_hidden[:,i]\n",
    "            \n",
    "            # Applying the activation function for the current layer\n",
    "            hidden_data = self.activation(pre_activation, activation_function)\n",
    "            \n",
    "            cummulative_input.append(hidden_data)\n",
    "\n",
    "        #From Hidden Layer to Output  ---------------------------------------------\n",
    "        output_data = np.dot(hidden_data, self.Weights_output) + self.Biases_output\n",
    "        \n",
    "        return output_data, hidden_data, cummulative_input\n",
    "    \n",
    "    def fermentation_model(self):\n",
    "        Phase_2_X = Kinetic_Model()\n",
    "        Time_array = exp_phase_2_extended['Time [hr]'].to_numpy()  #### Can change!!!!!!!!!#\n",
    "        #Init: S1 | S2 | I | B | P | V | X2\n",
    "        init = [exp_phase_2['S1 [g/L]'].iloc[0],exp_phase_2['S2 [g/L]'].iloc[0],exp_phase_2['I [g/L]'].iloc[0],\\\n",
    "                exp_phase_2['B [g/L]'].iloc[0],exp_phase_2['P [g/L]'].iloc[0],exp_phase_2['V [L]'].iloc[0],exp_phase_2['X2 [1/hr]'].iloc[0]]\n",
    "        sol_2_x,solt_2_x = Phase_2_X.solve_phase_2_with_X(init,Time_array,Teval=Time_array)\n",
    "        Model_data = pd.DataFrame(np.transpose(np.array([solt_2_x,sol_2_x[:,0],sol_2_x[:,1],sol_2_x[:,2],sol_2_x[:,4],sol_2_x[:,3] \\\n",
    "                          ,sol_2_x[:,6], exp_phase_2_extended['X1 [g/L]'].to_numpy() ,exp_phase_2_extended['Fin [L/hr]'].to_numpy() \\\n",
    "                            ,exp_phase_2_extended['T [K]'].to_numpy() ,sol_2_x[:,5]])))\n",
    "\n",
    "        Model_data.columns = ['Time [hr]', 'S1 [g/L]', 'S2 [g/L]', 'I [g/L]', 'P [g/L]', 'B [g/L]', 'X2 [1/hr]', 'X1 [g/L]', 'F_in [L/hr]', 'T [K]', 'V [L]']\n",
    "        Model_output = np.array(Model_data['S2 [g/L]'],Model_data['B [g/L]'],Model_data['P [g/L]'],\\\n",
    "                                Model_data['I [g/L]'],Model_data['X2 [1/hr]'],Model_data['V [L]'])\n",
    "        \n",
    "        return Model_output\n",
    "    \n",
    "    def Jacobian(self, inputs, output, cummulative_input, true_output, activation_function):\n",
    "        \n",
    "#         output_data,hidden_data,cummulative_input = forward_pass(self, inputs, activation_function)\n",
    "        \n",
    "#       \n",
    "        self.de_dp = np.zeros((true_outputs.shape[0],true_outputs.shape[1]))\n",
    "        for i in np.arange(true_outputs.shape[0]): #Across each column\n",
    "            for j in np.arange(true_outputs.shape[1]-1): #Across each row/point\n",
    "                self.de_dp[i,j] = (output[i,j+1] - 2*output[i,j] + output[i,j-1])/(true_outputs[i,j+1] - true_outputs[i,j-1])\n",
    "        \n",
    "        self.de_dAq_M = self.de_dp #A.15\n",
    "        \n",
    "        #A.14:\n",
    "        self.del_q_output =  self.de_dAq_M *self.activation_derivative(cummulative_input[-1]) #deq_dAqM* F'(nqM)\n",
    "        \n",
    "        self.deq_dW_output = np.dot(self.del_q_output, cummulative_input[-1])#del_qM * A_Q_M-1\n",
    "        \n",
    "        self.deq_dB_output = self.del_q_output\n",
    "        \n",
    "        self.del_q_hidden = np.zeros(self.del_q_output.shape + (self.no_hidden_layers,)) #Making a tensor to save for del_q for different layers\n",
    "        \n",
    "        self.del_q_hidden_values = self.del_q_output #Staritng del_q hidden at k+1 i.e the output so it can be used in the first iteration of equation\n",
    "        \n",
    "        \n",
    "        self.deq_dW_hidden =  np.zeros(self.deq_dW_output.shape+(self.no_hidden_layers,))\n",
    "        \n",
    "        self.deq_dB_hidden =  np.zeros(self.deq_dB_output.shape+(self.no_hidden_layers,))\n",
    "        \n",
    "        for i in range(self.no_hidden_layers):    \n",
    "            \n",
    "            self.del_q_hidden_values = np.dot(self.del_q_hidden_values\\\n",
    "                                         ,np.dot(self.activation_derivative(cummulative_input[-(i)])\\\n",
    "                                         ,self.Weights_hidden[:,:,i].T) )\n",
    "            \n",
    "            self.del_q_hidden[:,:,i] = self.del_q_hidden_values\n",
    "            \n",
    "            self.deq_dW_hidden[:,:,i] = np.dot(self.del_q_hidden_values, cummulative_input[-i])\n",
    "            \n",
    "            self.deq_dB_hidden [:,:,i] = self.del_q_hidden_values\n",
    "        \n",
    "#         deq_dW_hidden =  np.zeros(deq_dW_output.shape,self.no_hidden_layers)\n",
    "#         for i in range(self.no_hidden_layers):\n",
    "#             deq_dW_hidden[:,i] = np.dot(del_q_hidden[:,:,i], cummulative_input[-i])\n",
    "        \n",
    "        self.del_q_input = np.dot(self.del_q_hidden[:,:,-1],\\\n",
    "                             np.dot(self.activation_derivative(cummulative_input[-(self.no_hidden_layers+1)])\\\n",
    "                                        , self.Weights_hidden[:,:,i].T ))\n",
    "        \n",
    "        self.deq_dW_input = np.dot(self.del_q_input, cummulative_input[-(self.no_hidden_layers+1)])\n",
    "                \n",
    "        self.deq_dB_input = self.del_q_input\n",
    "        \n",
    "        def custom_merging_function(matrix1,matrix2): #Function to help merge A and B column by column of each at a time\n",
    "            matrix1 = matrix1.T\n",
    "            matrix2 = matrix2.T            \n",
    "            \n",
    "            # Get the number of columns in each matrix\n",
    "            n1 = matrix1.shape[1]\n",
    "            n2 = matrix2.shape[1]\n",
    "\n",
    "            \n",
    "            # Initialize an empty array to store the merged matrix\n",
    "            merged_matrix = np.empty((matrix1.shape[0], n1 + n2))\n",
    "    \n",
    "            # Initialize an empty array to store the merged matrix\n",
    "            merged_matrix = np.empty((matrix1.shape[0], n1 + n2))\n",
    "\n",
    "            # Merge the matrices column by column\n",
    "            for i in range(n1):\n",
    "                merged_matrix[:, i*2] = matrix1[:, i]\n",
    "            for j in range(n2):\n",
    "                merged_matrix[:, j*2 + 1] = matrix2[:, j]\n",
    "                \n",
    "            return merged_matrix\n",
    "            \n",
    "            \n",
    "        ##Creating Final Jacobian\n",
    "        #Starting with Input NN parameters\n",
    "        J = custom_merging_function(self.deq_dW_input,self.deq_dB_input)\n",
    "        \n",
    "        #Appending error derivatives for the hidden layer NN parameter\n",
    "        \n",
    "        for i in range(self.no_hidden_layers):\n",
    "            J = np.append(J,custom_merging_function(self.deq_dW_hidden[:,:,i],self.deq_dB_hidden[:,:,i]) ,axis = 1)\n",
    "        \n",
    "        #Appending error derivatives for the output layer NN parameter\n",
    "        J = np.append(J,custom_merging_function(self.deq_dW_output,self.deq_dB_output),axis = 1)\n",
    "        \n",
    "        print('\\nTotal Number of Neural Network Parameters: ',J.shape[1] )\n",
    "        print('----Jacobian Calculated----')\n",
    "        return J\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    def backward_pass(self, inputs, output, hidden_output, true_output, cummulative_input, activation_function):\n",
    "        # The Jacobian\n",
    "        J = self.Jacobian(inputs,output_data,cummulative_input,true_outputs,activation_function)\n",
    "        \n",
    "        # Error matrix \n",
    "        E = np.transpose(true_output - output)\n",
    "        \n",
    "        #The combination coefficient \n",
    "        mu_train = 0.1\n",
    "        \n",
    "        #Weight Correction::::\n",
    "        \n",
    "        #For the input weights\n",
    "        cov_matrix = (J[:,0].T* J[:,0])\n",
    "        covv = np.linalg.pinv( cov_matrix + mu_train* np.identity(cov_matrix.shape[0]) )        \n",
    "        np.dot(covv,(J[:,0]*E).T)\n",
    "#         self.Weights_input = \n",
    "    \n",
    "#         W_err_inputs =   \n",
    "        \n",
    "#         B_err_inputs =\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.Weights_input[] = np.random.randn(self.input_size, self.no_neurons_per_hidden_layer)\n",
    "#         self.Weights_hidden = np.random.randn(self.no_neurons_per_hidden_layer, self.no_neurons_per_hidden_layer, self.no_hidden_layers)\n",
    "#         self.Weights_output \n",
    "        \n",
    "        \n",
    "#         hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n",
    "#         hidden_delta = hidden_error * self.activation_derivative(hidden_output, activation_function)\n",
    "\n",
    "#         # Update weights and biases\n",
    "#         self.weights_hidden_output += np.dot(hidden_output.T, output_delta) * learning_rate\n",
    "#         self.biases_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "#         self.weights_input_hidden += np.dot(inputs.T, hidden_delta) * learning_rate\n",
    "#         self.biases_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "\n",
    "#     def train(self, inputs, true_outputs, epochs, learning_rate, activation_function):\n",
    "        \n",
    "#         inputs = inputs.T\n",
    "#         true_outputs = true_outputs.T\n",
    "        \n",
    "#         self.activation_function = activation_function\n",
    "        \n",
    "#         for epoch in range(epochs):\n",
    "#             # Forward pass\n",
    "#             output, hidden_output = self.forward_pass(inputs, activation_function)\n",
    "\n",
    "#             # Backward pass\n",
    "#             self.backward_pass(inputs, output, hidden_output, true_outputs, learning_rate, activation_function)\n",
    "\n",
    "#             # Compute and print the loss (MSE)\n",
    "#             loss = np.mean(np.square(true_outputs - output))\n",
    "#             if epoch % 100 == 0:\n",
    "#                 print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "#     def predict(self, inputs):\n",
    "#         inputs = inputs.T\n",
    "#         activation_function = self.activation_function\n",
    "#         output, _ = self.forward_pass(inputs, activation_function)\n",
    "#         return output.T\n",
    "\n",
    "# # Example data\n",
    "inputs = np.random.rand(48,9) * 0.5\n",
    "true_outputs = np.random.rand(48,3) # f(a=1, b=1) = (1*0^2 + 1*0^2) = 0, (1*1^2 + 1*1^2) = 2, ...\n",
    "\n",
    "#  input_size, no_hidden_layers, no_neurons_per_hidden_layer , output_size , no_data_points\n",
    "#  0 :input_size, \n",
    "#. 1 :no_hidden_layers, \n",
    "#. 2 :no_neurons_per_hidden_layer , \n",
    "#. 3 :output_size ,\n",
    "#. 4 :no_data_points.\n",
    "\n",
    "nn = NeuralNetwork(9,3,5,3,48)\n",
    "\n",
    "# # Create and train the neural network\n",
    "# nn = NeuralNetwork(input_shape=(9,48), hidden_shape=(6,48), output_shape=(3,48))\n",
    "# nn.train(inputs, true_outputs,learning_rate= 1e-3, epochs=10000, activation_function = 'sigmoid')\n",
    "\n",
    "# # Make predictions\n",
    "# predictions = nn.predict(inputs)\n",
    "# print(\"\\nPredictions:\")\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "a4cac747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "ff22d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data, hidden_data, cummulative_input = nn.forward_pass(inputs, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "474db73c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_phase_2_extended' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[676], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nn\u001b[38;5;241m.\u001b[39mfermentation_model()\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[675], line 77\u001b[0m, in \u001b[0;36mNeuralNetwork.fermentation_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfermentation_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     76\u001b[0m     Phase_2_X \u001b[38;5;241m=\u001b[39m Kinetic_Model()\n\u001b[0;32m---> 77\u001b[0m     Time_array \u001b[38;5;241m=\u001b[39m exp_phase_2_extended[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime [hr]\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()  \u001b[38;5;66;03m#### Can change!!!!!!!!!#\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m#Init: S1 | S2 | I | B | P | V | X2\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     init \u001b[38;5;241m=\u001b[39m [exp_phase_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS1 [g/L]\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],exp_phase_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS2 [g/L]\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],exp_phase_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI [g/L]\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\\\n\u001b[1;32m     80\u001b[0m             exp_phase_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB [g/L]\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],exp_phase_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP [g/L]\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],exp_phase_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV [L]\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],exp_phase_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX2 [1/hr]\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp_phase_2_extended' is not defined"
     ]
    }
   ],
   "source": [
    "nn.fermentation_model().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "e9c71eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 5)"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "cummulative_input[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "dfbc26e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetwork' object has no attribute 'del_q_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[656], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nn\u001b[38;5;241m.\u001b[39mdel_q_output\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NeuralNetwork' object has no attribute 'del_q_output'"
     ]
    }
   ],
   "source": [
    "nn.del_q_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec6569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "3031ad6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (48,3) (48,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[657], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_data, hidden_data, cummulative_input \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mforward_pass(inputs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m J \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mJacobian(inputs,output_data,cummulative_input,true_outputs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[654], line 88\u001b[0m, in \u001b[0;36mNeuralNetwork.Jacobian\u001b[0;34m(self, inputs, output, cummulative_input, true_output, activation_function)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mde_dAq_M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mde_dp \u001b[38;5;66;03m#A.15\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#A.14:\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdel_q_output \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mde_dAq_M \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_derivative(cummulative_input[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m#deq_dAqM* F'(nqM)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeq_dW_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdel_q_output, cummulative_input[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;66;03m#del_qM * A_Q_M-1\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeq_dB_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdel_q_output\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (48,3) (48,5) "
     ]
    }
   ],
   "source": [
    "J = nn.Jacobian(inputs,output_data,cummulative_input,true_outputs,'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "29047817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 30)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "1b378d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cov_matrix + mu_train* np.identity(cov_matrix.shape[0]) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "fd332bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix = (J[:,1].T* J[:,1])\n",
    "mu_train = 0.1\n",
    "covvvv = np.linalg.pinv( cov_matrix + mu_train* np.identity(cov_matrix.shape[0]) )\n",
    "covvvv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "2870c5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "a5f53b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covvvv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "c0f8d20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 9)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J[:, :9 * 2:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "def211bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(covvvv,np.dot(J[:, :3 * 2:2],E)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "47870dc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9,48) (48,48) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[560], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m E \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(true_outputs \u001b[38;5;241m-\u001b[39m out\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m----> 2\u001b[0m nn\u001b[38;5;241m.\u001b[39mWeights_input \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(covvvv,np\u001b[38;5;241m.\u001b[39mdot(J[:, :\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m2\u001b[39m],E))\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9,48) (48,48) "
     ]
    }
   ],
   "source": [
    " E = np.transpose(true_outputs - out.T)\n",
    "nn.Weights_input - np.dot(covvvv,np.dot(J[:, :3 * 2:2],E))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "b56aff27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 4)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Weights_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "fbfbdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.dot(Result ,nn.activation_derivative(cummulative_input[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "95f53e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.35553737e+06,  2.41622351e+07,  1.67994132e+07,\n",
       "         3.46229109e+06, -7.78521950e+06,  2.85752878e+07,\n",
       "        -4.24742292e+06, -9.31486771e+06, -1.01538346e+07,\n",
       "        -2.52023704e+06,  7.43899003e+06, -3.90004801e+07,\n",
       "        -2.19417689e+07,  2.15902817e+07, -1.25476738e+07,\n",
       "         9.43755712e+06,  1.32814031e+07, -1.79469663e+07,\n",
       "        -3.79403736e+06,  1.49922883e+07,  2.80855435e+07,\n",
       "        -7.01875744e+06, -1.11316884e+07,  2.35607964e+07,\n",
       "        -1.01643819e+07, -1.59558739e+07, -1.35343276e+04,\n",
       "         1.11002031e+07,  1.32637728e+06,  1.71888923e+05,\n",
       "         2.82008931e+07,  2.91504064e+07, -1.84642417e+07,\n",
       "         1.45974670e+07,  2.13055646e+07, -5.76588804e+06,\n",
       "        -1.09217493e+07,  1.35054113e+07,  3.27229161e+06,\n",
       "        -4.38930885e+06,  2.23070951e+07,  9.92963863e+06,\n",
       "         1.26136699e+07, -1.37450054e+07,  2.43579344e+07,\n",
       "         2.65745302e+06, -5.69742506e+06, -5.12151154e+06],\n",
       "       [ 8.18385901e+06, -2.68795896e+07, -1.86627670e+07,\n",
       "        -3.84080278e+06,  8.63872019e+06, -3.17916446e+07,\n",
       "         4.70323732e+06,  1.03792681e+07,  1.12903985e+07,\n",
       "         2.79541882e+06, -8.28910601e+06,  4.33372494e+07,\n",
       "         2.44116392e+07, -2.39988434e+07,  1.39616359e+07,\n",
       "        -1.04953120e+07, -1.47701138e+07,  1.99752150e+07,\n",
       "         4.22367282e+06, -1.66665992e+07, -3.12453886e+07,\n",
       "         7.81031870e+06,  1.23712548e+07, -2.61836047e+07,\n",
       "         1.13087879e+07,  1.77414525e+07,  6.28558017e+03,\n",
       "        -1.23388830e+07, -1.50849247e+06, -1.82778879e+05,\n",
       "        -3.13635910e+07, -3.24098106e+07,  2.05158597e+07,\n",
       "        -1.62496137e+07, -2.36787824e+07,  6.42815957e+06,\n",
       "         1.21481220e+07, -1.50188142e+07, -3.62579265e+06,\n",
       "         4.88618000e+06, -2.48051681e+07, -1.10311335e+07,\n",
       "        -1.40426868e+07,  1.52961731e+07, -2.70940962e+07,\n",
       "        -2.94419406e+06,  6.35633025e+06,  5.73409175e+06],\n",
       "       [ 1.52178212e+05, -4.96489015e+05, -3.44545052e+05,\n",
       "        -7.13759856e+04,  1.59572134e+05, -5.86489126e+05,\n",
       "         8.76184602e+04,  1.91703528e+05,  2.08170818e+05,\n",
       "         5.05109483e+04, -1.52658257e+05,  7.99344656e+05,\n",
       "         4.49529558e+05, -4.43060070e+05,  2.59204054e+05,\n",
       "        -1.93608014e+05, -2.71909573e+05,  3.69144402e+05,\n",
       "         7.81092682e+04, -3.06962912e+05, -5.77989021e+05,\n",
       "         1.42830387e+05,  2.28803154e+05, -4.83076018e+05,\n",
       "         2.08362167e+05,  3.28517040e+05,  1.67186655e+02,\n",
       "        -2.26706081e+05, -2.60991374e+04, -3.23460375e+03,\n",
       "        -5.77097820e+05, -5.98309449e+05,  3.78576446e+05,\n",
       "        -3.01047552e+05, -4.37224160e+05,  1.17346354e+05,\n",
       "         2.25298484e+05, -2.75872117e+05, -6.53652906e+04,\n",
       "         9.11244722e+04, -4.56661427e+05, -2.03188262e+05,\n",
       "        -2.60008120e+05,  2.83119153e+05, -4.99525239e+05,\n",
       "        -5.47073661e+04,  1.17192698e+05,  1.06378447e+05]])"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(out,np.dot(nn.activation_derivative(cummulative_input[-(0)])\\\n",
    "       , nn.Weights_hidden[:,:,0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "04b0255b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 48)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result = np.zeros((true_outputs.shape[0],true_outputs.shape[1]))\n",
    "for i in np.arange(true_outputs.shape[0]): #Across each column\n",
    "    for j in np.arange(true_outputs.shape[1]-1): #Across each row/point\n",
    "        Result[i,j] = (output[i,j+1] - 2*output[i,j] + output[i,j-1])/(true_outputs[i,j+1] - true_outputs[i,j-1])\n",
    "\n",
    "Result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dd4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "04d5c757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 48, 1)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3,48) + (1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "bdb8da88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(48, 5), (48, 5), (48, 5), (48, 5)]"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[arr.shape for arr in cummulative_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c9b34f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1230.84302623, -1763.54379407, -1388.42421649, -1326.86901639,\n",
       "         -523.1083589 , -1035.4201058 ,  -837.02532911, -1003.03378032,\n",
       "        -1033.24524912, -1462.745193  , -1266.52731987,  -870.59488179,\n",
       "        -1887.22371846, -1205.94731209,  -696.69937671,  -805.70602143,\n",
       "         -625.42220427, -1462.80000857, -1463.44991135, -1365.89521419,\n",
       "         -378.17761711, -2138.44881235, -1532.47361803, -1106.68206848,\n",
       "        -1573.24956286, -1156.66119895, -1355.75697514, -1957.85535432,\n",
       "        -1219.96731639,  -873.15306713,  -364.02263354, -1478.77911971,\n",
       "        -1248.22095029, -1138.98369586,  -945.98367671, -1016.08488052,\n",
       "        -1427.31475701, -1255.14363634,  -577.72780802, -1316.66001958,\n",
       "        -1100.22098599,  -478.23466118, -1676.24651037, -1070.5679705 ,\n",
       "         -899.6959804 ,  -168.65922421, -1937.97509967, -1084.61987595],\n",
       "       [  135.64192104,   204.83996263,  -359.00916291,   458.88795254,\n",
       "          563.97567137,  1251.57395733,  -230.61917834,   347.69882894,\n",
       "          689.83304792,   204.21606666,  -115.99770129,    52.30170168,\n",
       "           31.59496844,   386.20580369,   664.36181296,   463.26199805,\n",
       "          219.68742989,   -24.64623004,   251.34915163,   845.69474251,\n",
       "          179.28713037,  1297.38281955,  -132.7583068 ,   237.21441491,\n",
       "          203.59260526,   241.84550492,   204.12349355,   475.55165412,\n",
       "         -198.24831968,   255.07148465,   278.19751761,    21.63911924,\n",
       "          291.89655668,   -40.48867207,   312.72410666,    96.45188207,\n",
       "          213.07592368,   224.30438695,  1628.90112265,   471.75541471,\n",
       "          144.12365478,   -35.96352618,   257.71559109,   339.72533973,\n",
       "          345.36918445,    12.2282164 ,   654.21742938,   343.72472487],\n",
       "       [ -730.98838257, -1518.93703502, -1826.60321641, -1775.74160693,\n",
       "        -1502.59201382, -1195.51059436,  -579.32055709, -1266.77147368,\n",
       "        -1469.6837554 , -1826.38314285,  -255.24385131, -2467.11556893,\n",
       "        -1504.0630967 , -1557.27089678,  -990.42375248, -1252.04159542,\n",
       "        -1422.41154474, -1330.4999487 ,  -965.36446217,  -348.30588198,\n",
       "        -1262.13633174, -2730.26653921, -1521.19658773, -1346.5824983 ,\n",
       "         -903.39943242, -1140.96039671, -2312.46758086, -2782.91983908,\n",
       "        -2241.95090553,  -956.1352885 , -1007.80415714, -1093.83759238,\n",
       "        -1504.23244205, -1933.85400068,  -981.68256785, -2047.97164827,\n",
       "        -1460.88238994,  -984.63270799,  -861.90932299,  -808.89265299,\n",
       "        -2003.61861201, -1222.0471822 , -2148.74514778, -1814.00920838,\n",
       "         -684.81970309,  -665.89135377, -1085.26420154, -1016.15885128]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "23a434a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 48)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a4a7c6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(nn.weights_hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b2c4f1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights_hidden_layer_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "583eeed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.random.randn(2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a12a49ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2181649165787833"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52570f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
