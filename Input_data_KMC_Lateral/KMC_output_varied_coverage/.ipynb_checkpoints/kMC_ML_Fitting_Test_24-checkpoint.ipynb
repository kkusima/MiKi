{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224062de",
   "metadata": {},
   "source": [
    "***\n",
    "$$\\mathbf{\\text{Simulation/Experimental Output Processing and ML-MF Correction}}$$<br>\n",
    "$$\\mathbf{\\text{Author: Kenneth Kusima}}$$<br>\n",
    "$\\mathbf{\\text{Date: 06/01}}$<br>\n",
    "\n",
    "#### Note sw: Switching -> CO<->O2 ; CO*<->O* To match KMC specnum file\n",
    "\n",
    "\n",
    "#### It also |uses the MKM input files that match this order *_sw\n",
    "\n",
    "#### As well as the new test set KMC_NonDynamic_Data_iCovg_iRates_sw\n",
    "\n",
    "#### Switch the pressures accordingly CO <-> O2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf61d49",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Model being explored: Simple 4-step CO Oxidation}}:$<br>\n",
    "\n",
    "${\\text{Corresponding Micro Kinetic Model}}:$<br>\n",
    "***\n",
    "$$\\require{mhchem}$$       \n",
    "---\n",
    "Overall Reaction: \n",
    "$$ CO + \\frac{1}{2} O_2 {\\stackrel{\\tiny{\\textrm{Pt/Pd}}}{\\rightleftharpoons}} CO_2 $$\n",
    "---\n",
    "Note Reations in the Reaction Mechanism may be reversible or irreversible\n",
    "\n",
    "Reaction 1:&emsp;Adsorption of CO\n",
    "\n",
    "$$ CO + * \\rightleftharpoons CO^{*} $$\n",
    "\n",
    "Reaction 2:&emsp;Adsorption of $O_2$\n",
    "\n",
    "$$ O_2 + * \\rightleftharpoons {O_2}^{*} $$\n",
    "\n",
    "Reaction 3:&emsp;Dissociation of ${O_2}^*$ \n",
    "\n",
    "$$ {O_2}^* + * \\rightleftharpoons 2{O}^* $$\n",
    "\n",
    "Reaction 4:&emsp;Surface Reaction of $CO$ and $O_2$  \n",
    "\n",
    "$$ {CO}^{*} + {O}^{*} \\rightleftharpoons CO_2 + 2* $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675875ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bff0283",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a078f",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a><br>\n",
    " # Table of Contents  \n",
    "1. [Loading in the labeled simulation folders](#1)   \n",
    "    1. [Checking all simulations were completed as expected](#1.1)\n",
    "1. [Developing ML Training Dataset for rate correction](#2) \n",
    "    1. [Generating Experimental Data Dictionary](#2.1) \n",
    "    1. [Generating MF-MKM Data Dictionary](#2.2)     \n",
    "    1. [Creating Features](#2.3)      \n",
    "        C1. [Log ratio](#2.3.1)     \n",
    "        C2. [Percent Difference](#2.3.2)    \n",
    "        \n",
    "    1. [Creating Input/Feature Tensor](#2.4)\n",
    "    1. [Extracting Full X (Feature) and Y(Target) datasets](#2.5)\n",
    "    1. [Performing Train/Test X and Y Split datasets](#2.6)\n",
    "1. [Modelling](#3)\n",
    "1. [Describing Possible Machine Learning Model Algorithms](#4)\n",
    "1. [Selecting and Training the Model](#5)\n",
    "1. [Importing External/Experimental Data to be used in the model](#6)\n",
    "    1. [Generating corresponding MF-MKModel](#6.1) \n",
    "    1. [Predicting Machine-Learned Mean-Field Corrections](#6.2)\n",
    "    1. [ML Correction to MF-MKModel](#6.3)\n",
    "    1. [Evaluating the ML model prediction](#6.4)\n",
    "    1. [Plotting results](#6.5)\n",
    "    \n",
    "1. [Exploring and Evaluating possible ML options](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e78438",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"1\"></a> \n",
    "## 1. Loading in the labeled simulation folders\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4297924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/klkusima/Library/CloudStorage/OneDrive-UniversityOfHouston/MiKi/Input_data_KMC_Lateral/KMC_output_varied_coverage'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f1258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of simulations: 55\n",
      "['Sim_A_0_B_77', 'Sim_A_44_B_55', 'Sim_A_55_B_22', 'Sim_A_22_B_77', 'Sim_A_88_B_11', 'Sim_A_22_B_22', 'Sim_A_33_B_0', 'Sim_A_33_B_55', 'Sim_A_0_B_22', 'Sim_A_22_B_0', 'Sim_A_66_B_11', 'Sim_A_11_B_44', 'Sim_A_11_B_88', 'Sim_A_11_B_11', 'Sim_A_0_B_100', 'Sim_A_77_B_11', 'Sim_A_11_B_33', 'Sim_A_11_B_66', 'Sim_A_66_B_33', 'Sim_A_44_B_0', 'Sim_A_44_B_22', 'Sim_A_55_B_0', 'Sim_A_100_B_0', 'Sim_A_22_B_55', 'Sim_A_0_B_55', 'Sim_A_33_B_22', 'Sim_A_33_B_66', 'Sim_A_0_B_11', 'Sim_A_44_B_33', 'Sim_A_55_B_44', 'Sim_A_66_B_0', 'Sim_A_0_B_0', 'Sim_A_22_B_11', 'Sim_A_55_B_11', 'Sim_A_22_B_44', 'Sim_A_33_B_33', 'Sim_A_0_B_88', 'Sim_A_0_B_44', 'Sim_A_11_B_22', 'Sim_A_66_B_22', 'Sim_A_11_B_77', 'Sim_A_77_B_0', 'Sim_A_88_B_0', 'Sim_A_11_B_0', 'Sim_A_11_B_55', 'Sim_A_77_B_22', 'Sim_A_44_B_44', 'Sim_A_0_B_66', 'Sim_A_33_B_11', 'Sim_A_22_B_66', 'Sim_A_55_B_33', 'Sim_A_22_B_33', 'Sim_A_44_B_11', 'Sim_A_0_B_33', 'Sim_A_33_B_44']\n",
      "CPU times: user 505 µs, sys: 646 µs, total: 1.15 ms\n",
      "Wall time: 725 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Sim_folder_names = []\n",
    "i = 0\n",
    "for file in glob.glob(\"Sim_*\"):\n",
    "    Sim_folder_names.append(file)\n",
    "    i+=1\n",
    "print('Number of simulations:',i)\n",
    "print(Sim_folder_names)\n",
    "#os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b205d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_init_coverages = np.empty([len(Sim_folder_names),4])\n",
    "#Remember: A='O*'; B='CO*'\n",
    "#Reading A and B initial coverages from the KMC simulation input coverage files\n",
    "c = 0 #counter\n",
    "for s in Sim_folder_names:\n",
    "    set_coverages = []\n",
    "    for i in np.arange(len(s)):\n",
    "        if i<(len(s)-2) and s[i].isdigit() and (s[i+1]).isdigit() and (s[i+2]).isdigit():\n",
    "            cov_triple = int(s[i:i+3])\n",
    "            set_coverages.append(cov_triple)\n",
    "            \n",
    "        elif i<(len(s)-1) and s[i].isdigit() and (s[i+1]).isdigit()and not((s[i-1]).isdigit()):\n",
    "            cov_double = int(s[i:i+2])\n",
    "            set_coverages.append(cov_double)\n",
    "            \n",
    "#             print(cov_double)\n",
    "        elif s[i].isdigit() and not((s[i-1]).isdigit()) and not((s[i-2]).isdigit()):\n",
    "            cov_single = int(s[i])\n",
    "            set_coverages.append(cov_single)\n",
    "                                #A_O*_covg,     B_CO*_covg,     O2*_covg,*_covg\n",
    "    set_init_coverages[c,:] = [set_coverages[0],set_coverages[1],0,100-sum(set_coverages)]\n",
    "    c+=1 #counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b63683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/klkusima/Library/CloudStorage/OneDrive-UniversityOfHouston/MiKi/Input_data_KMC_Lateral/KMC_output_varied_coverage'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67d57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see match\n",
    "## Copying all the other input files into the different simulation folders\n",
    "# Extracting initial coverages\n",
    "#Remember: A='CO*'; B='O*'\n",
    "n_points = 500 #From KMC simulation \n",
    "n_gas_species = 3 #From KMC simulation\n",
    "n_surf_species = 4 #From KMC simulation\n",
    "\n",
    "Exp_init_coverages = np.empty([len(Sim_folder_names),n_surf_species])\n",
    "c = 0 #counter\n",
    "for s in Sim_folder_names:\n",
    "    os.chdir(s)\n",
    "    file=open('specnum_output.txt','r').readlines() #Reading in the relevant file\n",
    "    b=[]\n",
    "    for i in np.arange(len(file)): \n",
    "        b.append(file[i].split())                   #Dividing the rows into columns\n",
    "    o = pd.DataFrame(data=b)                        #Final output\n",
    "\n",
    "#     print(o)\n",
    "    #Extracting Number of Sites from the general_output file:\n",
    "    inp=open('general_output.txt','r').readlines()\n",
    "    for i in np.arange(len(inp)): \n",
    "        if 'Total number of lattice sites:' in inp[i]:\n",
    "            val = i  #Line in text file where sentence is present\n",
    "\n",
    "    sites = int(inp[val][35:])\n",
    "    \n",
    "    #Finding number of surface species\n",
    "    headings = (o.iloc[0,:])\n",
    "    n_ss = sum('*' in h for h in headings) #Number of surface species\n",
    "    \n",
    "    #Finding number of gas species\n",
    "    n_gs = len(headings)-5-n_ss\n",
    "    \n",
    "    #Adding column to calculate number of empty sites\n",
    "    n_c=(len(o.iloc[0,:])) #number of current columns\n",
    "    o[n_c]=\" \"           #Creating new empty column \n",
    "    o.iloc[0,n_c]=\"*\"    #Labelling the new empty column \n",
    "\n",
    "    st = 0 #Initializing empty site coverage vector\n",
    "\n",
    "\n",
    "    for i in range(len(o.iloc[1:])):\n",
    "        if n_ss==0:\n",
    "            site = sites\n",
    "        else:\n",
    "            for j in range(n_ss):\n",
    "                st = st + float(o.iloc[i+1,5+j]) #Calculating no. of empty sites #Asuming empty sites are first to be reportes (i.e @5)\n",
    "            site = sites - st\n",
    "            st = 0\n",
    "        o.iloc[i+1,n_c] = site\n",
    "    \n",
    "    Sspecies = []\n",
    "    for i in range(n_ss):\n",
    "        Sspecies.append(5+i) \n",
    "    Sspecies.append(len(o.iloc[1,:])-1)#Including empty sites\n",
    "\n",
    "    #Calculating itme:\n",
    "    Gtime = o[2][1:].astype(float) \n",
    "    #Calculating coverages:\n",
    "    Scoverages = np.empty([len(o.iloc[:,1])-1,len(Sspecies)])\n",
    "    for i in range(len(Scoverages[1,:])):\n",
    "        Scoverages[:,i] = o[Sspecies[i]][1:].astype(float)/sites\n",
    "        \n",
    "    exp_init_covg = []\n",
    "    for i in np.arange(n_surf_species):    #A_O*_covg,     B_CO*_covg,     O2*_covg, *_covg\n",
    "        exp_init_covg.append(Scoverages[0,i])\n",
    "        \n",
    "    Exp_init_coverages[c,:] = exp_init_covg\n",
    "    \n",
    "    c+=1\n",
    "    \n",
    "    \n",
    "    os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d061af",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a> \n",
    "## 1.1 Checking all simulations were completed as expected\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54239bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMULATIONS MATCH AS EXPECTED\n"
     ]
    }
   ],
   "source": [
    "if np.shape(set_init_coverages) != np.shape(Exp_init_coverages):\n",
    "    raise Exception('Not all simulations have been completed successfully')\n",
    "    \n",
    "for i in np.arange(np.shape(set_init_coverages)[0]):\n",
    "    for j in np.arange(np.shape(set_init_coverages)[1]):\n",
    "        norm_val = set_init_coverages[i,j]\n",
    "        exp_val = round(Exp_init_coverages[i,j])\n",
    "        if not( norm_val + 1 > exp_val) and not(norm_val - 1 < exp_val): #i.e if not within range\n",
    "            raise Exception('Initial coverages used in the simulation are not the same as it was set')\n",
    "            \n",
    "        if (i==(np.shape(set_init_coverages)[0] - 1) and j==(np.shape(set_init_coverages)[1] - 1)):\n",
    "            print('SIMULATIONS MATCH AS EXPECTED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6afb0",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2\"></a> \n",
    "## 2. Developing ML Training Dataset for rate correction\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b1f8c",
   "metadata": {},
   "source": [
    "## Dictionary formats:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "676d8e3f",
   "metadata": {},
   "source": [
    "#Dictionaries to be used\n",
    "\n",
    "data_KMC_dict = {'init_covg': init_coverages, \n",
    "                    'sim_time': KMC_time_Array, \n",
    "                     'covg_prof': Covg, \n",
    "                     'iRates': Rates}\n",
    "         \n",
    "data_MKM_dict = {'init_covg': MKM_init_coverages, \n",
    "                    'sim_time': time_MKM_Array, \n",
    "                     'covg_prof': MKM_Covg, \n",
    "                     'iRates': MKM_Rates}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2477c7",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.1\"></a> \n",
    "## 2.A  Generating Experimental Data Dictionary\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6452c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe3bb6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 922 ms, sys: 9.18 ms, total: 932 ms\n",
      "Wall time: 938 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Copying all the other input files into the different simulation folders\n",
    "# Extracting initial coverages\n",
    "#Remember: A='O*'; B='CO*'\n",
    "n = len(Sim_folder_names)\n",
    "\n",
    "Covg = np.zeros((n,n_points,n_surf_species)) #O*, CO*, O2*, *\n",
    "Rates = np.zeros((n,n_points,n_gas_species)) #O2, CO, CO2\n",
    "KMC_time_Array = np.zeros((n,n_points))\n",
    "init_coverages = np.empty([n,n_surf_species])\n",
    "c = 0 #counter for number of simulation (folders)\n",
    "\n",
    "for s in Sim_folder_names:\n",
    "    os.chdir(s)\n",
    "    file=open('specnum_output.txt','r').readlines() #Reading in the relevant file\n",
    "    b=[]\n",
    "    for i in np.arange(len(file)): \n",
    "        b.append(file[i].split())                   #Dividing the rows into columns\n",
    "    o = pd.DataFrame(data=b)                        #Final output\n",
    "\n",
    "#     print(o)\n",
    "    #Extracting Number of Sites from the general_output file:\n",
    "    inp=open('general_output.txt','r').readlines()\n",
    "    for i in np.arange(len(inp)): \n",
    "        if 'Total number of lattice sites:' in inp[i]:\n",
    "            val = i  #Line in text file where sentence is present\n",
    "\n",
    "    sites = int(inp[val][34:])\n",
    "    \n",
    "    #Finding number of surface species\n",
    "    headings = (o.iloc[0,:])\n",
    "    n_ss = sum('*' in h for h in headings) #Number of surface species\n",
    "    \n",
    "    #Finding number of gas species\n",
    "    n_gs = len(headings)-5-n_ss\n",
    "    \n",
    "    #Adding column to calculate number of empty sites\n",
    "    n_c=(len(o.iloc[0,:])) #number of current columns\n",
    "    o[n_c]=\" \"           #Creating new empty column \n",
    "    o.iloc[0,n_c]=\"*\"    #Labelling the new empty column \n",
    "\n",
    "    st = 0 #Initializing empty site coverage vector\n",
    "\n",
    "\n",
    "    for i in range(len(o.iloc[1:])):\n",
    "        if n_ss==0:\n",
    "            site = sites\n",
    "        else:\n",
    "            for j in range(n_ss):\n",
    "                st = st + float(o.iloc[i+1,5+j]) #Calculating no. of empty sites #Asuming empty sites are first to be reportes (i.e @5)\n",
    "            site = sites - st\n",
    "            st = 0\n",
    "        o.iloc[i+1,n_c] = site\n",
    "    \n",
    "    Sspecies = []\n",
    "    for i in range(n_ss):\n",
    "        Sspecies.append(5+i) \n",
    "    Sspecies.append(len(o.iloc[1,:])-1)#Including empty sites\n",
    "\n",
    "    #Calculating itme:\n",
    "    Gtime = o[2][1:].astype(float) \n",
    "    \n",
    "    #Calculating coverages:\n",
    "    Scoverages = np.empty([len(o.iloc[:,1])-1,len(Sspecies)])\n",
    "    for i in range(len(Scoverages[1,:])):\n",
    "        Scoverages[:,i] = o[Sspecies[i]][1:].astype(float)/sites\n",
    "        \n",
    "    Gspecies = []\n",
    "    for i in range(n_gs):\n",
    "        Gspecies.append(5+n_ss+i) \n",
    "        \n",
    "    #Extracting the number of gas species molecules:    \n",
    "    Gnmol = np.empty([len(o.iloc[:,1])-1,len(Gspecies)])\n",
    "    for i in range(len(Gnmol[1,:])):\n",
    "        Gnmol[:,i] = o[Gspecies[i]][1:].astype(float)\n",
    "    \n",
    "    ### Calculating the instantaneous rates of profuction (i.e grad/sites)\n",
    "    TOF_GS = np.empty([len(o.iloc[:,1])-1,len(Gspecies)]) #initializing an array of instantaneous TOFs for gaseous species\n",
    "\n",
    "    for i in np.arange(len(Gspecies)):\n",
    "        grads = np.gradient(Gnmol[:,i],Gtime,edge_order=2)\n",
    "        TOF_GS[:,i] = grads/sites\n",
    "    \n",
    "    \n",
    "    #initializing TOF for gas species\n",
    "    STOF = np.empty([n_points,n_gas_species])\n",
    "    gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "    gs_names_colmn = []\n",
    "    \n",
    "    for i in np.arange(n_gas_species): #Collecting TOFs\n",
    "        STOF[:,i] = pd.Series(TOF_GS[:,i])\n",
    "        \n",
    "    for i in gs_names: #Collecting gas names\n",
    "        gs_names_colmn.append('R_'+i)\n",
    "    \n",
    "    Rates_p = pd.DataFrame(STOF,\n",
    "                    columns = gs_names_colmn)\n",
    "\n",
    "    init_covg = []\n",
    "    for i in np.arange(n_surf_species):    #A_O*_covg,     B_CO*_covg,     O2*_covg, *_covg\n",
    "        init_covg.append(Scoverages[0,i])\n",
    "        \n",
    "    init_coverages[c,:]= init_covg #Initial coverages\n",
    "    \n",
    "    KMC_time_Array[c,:]= Gtime #Time matrix\n",
    "     \n",
    "    Covg[c,:,:] = Scoverages #Coverage profile tensor\n",
    "    \n",
    "    Rates[c,:,:] = Rates_p\n",
    "    \n",
    "    c+=1\n",
    "    \n",
    "    os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir)) #Changes directory back to where this script is\n",
    "\n",
    "#https://stackoverflow.com/questions/49881570/python-dictionaries-appending-arrays-to-a-dictionary-for-a-specific-key\n",
    "data_KMC_dict = {'init_covg': init_coverages, 'sim_time': KMC_time_Array, 'covg_prof': Covg, 'iRates': Rates}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94108ede",
   "metadata": {},
   "source": [
    "## Starting to Create ML dataset\n",
    "### x:n_features ; y = n_points ; z = n_simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f803a",
   "metadata": {},
   "source": [
    "<a id=\"2.4\"></a> \n",
    "## 2.D  Creating Input/Feature Tensor\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1077f0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 2.72 ms, total: 22.7 ms\n",
      "Wall time: 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Creating Simulation file names input\n",
    "\n",
    "Sim_names_tens = np.empty((n,n_points,1),dtype=np.dtype('U100'))\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(n_points):\n",
    "        Sim_names_tens[i,j,:] = Sim_folder_names[i]\n",
    "\n",
    "## Creating Init coverages tensor input\n",
    "ini_covg_tens = np.empty((n,n_points,n_surf_species),dtype=float)\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(n_points):\n",
    "        ini_covg_tens[i,j,:] = data_KMC_dict['init_covg'][i,:]\n",
    "\n",
    "## Creating time tensor input\n",
    "sim_time_tens = np.empty((n,n_points,1),dtype=float)\n",
    "for i in np.arange(n):\n",
    "    for z in np.arange(1):\n",
    "        sim_time_tens[i,:,z] = data_KMC_dict['sim_time'][i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49520af1",
   "metadata": {},
   "source": [
    "## Tenosr_To_Array Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a40d6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tensor_To_Array(Sim_tens):\n",
    "    a = Sim_tens\n",
    "    m,n,r = a.shape\n",
    "    sim_arr = np.column_stack((np.repeat(np.arange(m),n),a.reshape(m*n,-1)))\n",
    "    return sim_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772afea3",
   "metadata": {},
   "source": [
    "## Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb94aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(Tensor_To_Array(Sim_names_tens),columns= ['Sim_ndex','Sim_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46997abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding initial coverages\n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df['Init_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(ini_covg_tens))[1+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaa5f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding time\n",
    "out_df['Time'] = pd.DataFrame(Tensor_To_Array(sim_time_tens))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7764725",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding KMC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80651579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding coverage profiles of surface species\n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df['KMC_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(data_KMC_dict['covg_prof']))[1+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b13ace6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding iRates profiles of gaseous species\n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df['KMC_iRates_'+spec] = pd.DataFrame(Tensor_To_Array(data_KMC_dict['iRates']))[1+i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256884dc",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.2\"></a> \n",
    "## 2.B  Generating MF-MKModel Data Dictionary\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dd4156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass is conserved. \n",
      "\n",
      "CPU times: user 239 ms, sys: 67.9 ms, total: 307 ms\n",
      "Wall time: 441 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from main import *\n",
    "MKM = MKModel('Atomic_sw.csv','Stoich_sw.csv','Param_sw.csv')\n",
    "MKM.set_rxnconditions(Pr=[(1.0e-4*0.1),(1.0e-4*1.0e-5), 0]) #From KMC #Make sure it matches 02 CO CO2\n",
    "MKM_init_coverages = np.empty([len(Sim_folder_names),n_surf_species])\n",
    "\n",
    "def MKModelling(*fit_params):\n",
    "    n_points = 500 #From KMC simulation \n",
    "    n_gas_species = 3 #From KMC simulation\n",
    "    n_surf_species = 4 #From KMC simulation\n",
    "    MKM_Covg = np.zeros((n,n_points,n_surf_species)) # O*,CO*, O2*, * #Make sure KMC order of species matches MKM inputs\n",
    "    MKM_Rates = np.zeros((n,n_points,n_gas_species)) #O2, CO, CO2     #Make sure KMC order of species matches MKM inputs\n",
    "    time_MKM_Array = np.zeros((n,n_points))\n",
    "\n",
    "    MKM.set_limits_of_integration(Ti=data_KMC_dict['sim_time'][0][0],Tf=data_KMC_dict['sim_time'][-1][-1])\n",
    "    \n",
    "    MKM.k = np.array(fit_params)\n",
    "    \n",
    "    #Remember: A='CO*'; B='O*'\n",
    "    #Reading A and B initial coverages from the KMC simulation input coverage file names!\n",
    "    c = 0 #counter\n",
    "    for s in Sim_folder_names:\n",
    "        set_coverages = []\n",
    "        for i in np.arange(len(s)):\n",
    "            if i<(len(s)-2) and s[i].isdigit() and (s[i+1]).isdigit() and (s[i+2]).isdigit():\n",
    "                cov_triple = int(s[i:i+3])\n",
    "                set_coverages.append(cov_triple)\n",
    "\n",
    "            elif i<(len(s)-1) and s[i].isdigit() and (s[i+1]).isdigit()and not((s[i-1]).isdigit()):\n",
    "                cov_double = int(s[i:i+2])\n",
    "                set_coverages.append(cov_double)\n",
    "\n",
    "            elif s[i].isdigit() and not((s[i-1]).isdigit()) and not((s[i-2]).isdigit()):\n",
    "                cov_single = int(s[i])\n",
    "                set_coverages.append(cov_single)\n",
    "                                    #A_O*_covg,     B_CO*_covg,     O2*_covg,*_covg  #Note: Special case: Simulation naming switches from KMC and MKM order\n",
    "        init_covgs = [set_coverages[0]/100,set_coverages[1]/100,0,(100-sum(set_coverages))/100]\n",
    "        \n",
    "        MKM.set_initial_coverages(init=init_covgs)\n",
    "        MKM_init_coverages[c,:] = [float(i) for i in init_covgs]\n",
    "        \n",
    "        sola,solta = MKM.solve_coverage(Tf_eval=data_KMC_dict['sim_time'][0],plot=False)\n",
    "        time_MKM_Array[c,:]= solta #Time matrix\n",
    "        MKM_Covg[c,:,:] = sola #Coverage profile tensor\n",
    "\n",
    "        solb,soltb = MKM.solve_rate_production(Tf_eval=data_KMC_dict['sim_time'][0],plot=False)\n",
    "        MKM_Rates[c,:,:] = solb[:,0:n_gas_species] \n",
    "\n",
    "        c+=1 #counter\n",
    "    return {'init_covg': MKM_init_coverages, 'sim_time': time_MKM_Array, 'covg_prof': MKM_Covg, 'iRates': MKM_Rates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6751401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Fitting rate constant function due to the feature = iRates\n",
    "def MKM_k_fitting(x,*fit_params,feature = 'iRates'):\n",
    "    data_MKM_dict  = MKModelling(*fit_params)    \n",
    "    return np.reshape(data_MKM_dict[feature],data_MKM_dict[feature].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9ef4e",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.3.1\"></a> \n",
    "## 2.B.1 Optimizing Rate Constant:\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebabe7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_vals = np.array([1.48307412e+01, 1.39142897e+01, 8.20673617e+00, 3.01914788e+06, \n",
    "                         2.43999387e+04, 6.55211905e-01, 3.05777979e+00, 1.00000000e-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd051b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lat_fit_params = np.array([1.48307412e+01, 1.39142897e+01, 8.20673617e+00, 3.01914788e+06, \n",
    "                         2.43999387e+04, 6.55211905e-01, 3.05777979e+00, 1.00000000e-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f36a272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_values = data_KMC_dict['sim_time'] #Normalized Input Time variables (Independent Variable) (eg. KMC Time)\n",
    "y_values = np.reshape(data_KMC_dict['iRates'],data_KMC_dict['iRates'].size) #Normalized Input Dependent variable(s) (eg. KMC coverages)\n",
    "\n",
    "\n",
    "# params, params_covariance = optimize.curve_fit(MKM_k_fitting, x_values, y_values\n",
    "#                                             ,method = 'trf', bounds=(0,1e10), maxfev=1e3, xtol=1e-3, ftol=1e-3\n",
    "#                                             ,p0=initial_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1236ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the KMC fitting attempt\n",
    "##Perfect Fits\n",
    "\n",
    "params = initial_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0732b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MKM.ODE_Tolerances(Dplace=50,reltol=1e-5,abstol=1e-8)\n",
    "data_MKM_dict = MKModelling(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e823252",
   "metadata": {},
   "outputs": [],
   "source": [
    "MKM.init_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495e66a",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.3.2\"></a> \n",
    "## Adding MKM to dataframe\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dccf20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding coverage profiles of surface species\n",
    "surf_names = (o.iloc[0,Sspecies].tolist())\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    out_df['MKM_Covg_'+spec] = pd.DataFrame(Tensor_To_Array(data_MKM_dict['covg_prof']))[1+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding iRates profiles of gaseous species\n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df['MKM_iRates_'+spec] = pd.DataFrame(Tensor_To_Array(data_MKM_dict['iRates']))[1+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac328b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc81f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GETTING A LIST OF SIMULATION INDEXES AND SIMULATIONS\n",
    "new_Df = out_df.loc[:, ['Sim_ndex', 'Sim_names']]\n",
    "new_Df['Sim_ndex'] = new_Df['Sim_ndex'].astype(int)\n",
    "SIM_LIST = new_Df.groupby(['Sim_ndex'], as_index=False).max()\n",
    "SIM_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90880662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## RMSE Evaluation of Fit\n",
    "# from math import sqrt\n",
    "import numpy as np\n",
    "# rmse_fit_covg = []\n",
    "# rmse_fit_iRates = []\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_matrix = []\n",
    "for i in np.arange(len(set(out_df['Sim_ndex']))):\n",
    "    \n",
    "    df = out_df.loc[out_df['Sim_ndex'] == str(i)]\n",
    "    \n",
    "    #calculating covg  ---------------------------------------------------------------------------------\n",
    "    df = out_df.loc[out_df['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "    kmc_dat_covg = df[[col for col in df if 'KMC_Covg' in col]] #Extracting KMC comp data \n",
    "    mkm_dat_covg = df[[col for col in df if 'MKM_Covg' in col]] #Extracting MKM comp data \n",
    "    \n",
    "    ls = kmc_dat_covg.columns.to_list()\n",
    "    covg_nm = [string[3:] for string in ls] #surface_species names\n",
    "     \n",
    "    rmse_covg = []\n",
    "    for i in np.arange(len(covg_nm)):\n",
    "        rmse_covg.append(sqrt(mean_squared_error(kmc_dat_covg['KMC'+covg_nm[i]], mkm_dat_covg['MKM'+covg_nm[i]])))\n",
    "        \n",
    "    \n",
    "    #calculating irates ---------------------------------------------------------------------------------\n",
    "    \n",
    "    kmc_dat_irates = df[[col for col in df if 'KMC_iRates' in col]] #Extracting KMC comp data \n",
    "    mkm_dat_irates = df[[col for col in df if 'MKM_iRates' in col]] #Extracting MKM comp data \n",
    "    \n",
    "    ls = kmc_dat_irates.columns.to_list()\n",
    "    irates_nm = [string[3:] for string in ls] #gas_species names\n",
    "    \n",
    "    rmse_irates = []\n",
    "    for i in np.arange(len(irates_nm)):\n",
    "        rmse_irates.append(sqrt(mean_squared_error(kmc_dat_irates['KMC'+irates_nm[i]], mkm_dat_irates['MKM'+irates_nm[i]])))\n",
    "        \n",
    "    rmse_matrix.append(rmse_covg+rmse_irates)\n",
    "    \n",
    "    rmse_names = covg_nm+irates_nm\n",
    "    \n",
    "#Creating the RMSE Dataframe\n",
    "\n",
    "RMSE_Dataframe = pd.DataFrame(list(set(out_df['Sim_names'])), columns = ['Sim_names'])\n",
    "\n",
    "for i in np.arange(len(rmse_names)):\n",
    "    spec = rmse_names[i]\n",
    "    RMSE_Dataframe['RMSE'+spec] = pd.DataFrame(rmse_matrix).applymap(lambda x: round(x, 3))[i]\n",
    "\n",
    "RMSE_Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ff550",
   "metadata": {},
   "source": [
    "# Visual Evaluation of Fitting Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee498d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Part 1: Choose the feature of which you we will compare the k-opt values\n",
    "\n",
    "# Comp = 'iRates'\n",
    "Comp = 'Covg'\n",
    "colors = ['b','g','m','r','c','y','k'] \n",
    "\n",
    "print('Comparison of KMC vs fitted-k MKM results for' + Comp)\n",
    "\n",
    "#Part 2: Plot comparison results for fitting analysis\n",
    "for i in np.arange(len(set(out_df['Sim_ndex']))): #For each simulation:\n",
    "        #Extracting KMC results: ------------------------------------------------\n",
    "        df = out_df.loc[out_df['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        kmc_dat = df[[col for col in df if 'KMC_'+Comp in col]].to_numpy() #Extracting KMC comp data as array\n",
    "        Time = df['Time'].to_numpy()\n",
    "\n",
    "        #Plotting KMC result : ------------------------------------------------          \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        for i in np.arange(len(kmc_dat[0,:])):\n",
    "            ax.plot(Time, kmc_dat[:,i],colors[i]+'--')\n",
    "                        \n",
    "        if Comp =='iRates':\n",
    "            leg_nd = (o.iloc[0,Gspecies].tolist())\n",
    "            ax.set_ylim([-0.2,0.2])\n",
    "        elif Comp == 'Covg':\n",
    "            leg_nd = (o.iloc[0,Sspecies].tolist())\n",
    "            \n",
    "        ax.set_xlabel('Time, t, [s]')\n",
    "        if Comp =='iRates':\n",
    "            ax.set_ylabel(r\"Rates of Production, $R_i$\")\n",
    "            ax.set_title('Rates of production versus Time_ for Simulation_'+ df['Sim_ndex'].iloc[i] +': _'+df['Sim_names'].iloc[0]+'| A:CO* ; B:O*')\n",
    "        elif Comp == 'Covg':\n",
    "            ax.set_ylabel(r\"Coverage, $\\theta_i, [ML]$\")\n",
    "            ax.set_title('Coverages versus Time_for Simulation_'+ df['Sim_ndex'].iloc[i] +': _'+df['Sim_names'].iloc[0]+'| A:CO* ; B:O*')\n",
    "        \n",
    "        \n",
    "        #Extracting MKM results: ------------------------------------------------\n",
    "        mkm_dat = df[[col for col in df if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        Time = df['Time'].to_numpy()\n",
    "            \n",
    "            \n",
    "        #Adding to the plot, MKM result : ------------------------------------------------     \n",
    "        for i in np.arange(len(mkm_dat[0,:])):\n",
    "            ax.plot(Time, mkm_dat[:,i],colors[i]+'-')\n",
    "        \n",
    "        #Plotting all the legends together\n",
    "        ax.legend([f\"{string}_KMC\" for string in leg_nd]+[f\"{string}_MKM\" for string in leg_nd],fontsize=10, loc='upper right',facecolor='white', edgecolor ='black', framealpha=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a09bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Part 1: Choose the feature of which you we will compare the k-opt values\n",
    "\n",
    "Comp = 'iRates'\n",
    "# Comp = 'Covg'\n",
    "colors = ['b','g','m','r','c','y','k'] \n",
    "\n",
    "print('Comparison of KMC vs fitted-k MKM results for' + Comp)\n",
    "\n",
    "#Part 2: Plot comparison results for fitting analysis\n",
    "for i in np.arange(len(set(out_df['Sim_ndex']))): #For each simulation:\n",
    "        #Extracting KMC results: ------------------------------------------------\n",
    "        df = out_df.loc[out_df['Sim_ndex'] == str(i)] #Extracting dataframe only corresponding to simulation i\n",
    "        kmc_dat = df[[col for col in df if 'KMC_'+Comp in col]].to_numpy() #Extracting KMC comp data as array\n",
    "        Time = df['Time'].to_numpy()\n",
    "\n",
    "        #Plotting KMC result : ------------------------------------------------          \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        for i in np.arange(len(kmc_dat[0,:])):\n",
    "            ax.plot(Time, kmc_dat[:,i],colors[i]+'--')\n",
    "                        \n",
    "        if Comp =='iRates':\n",
    "            leg_nd = (o.iloc[0,Gspecies].tolist())\n",
    "            ax.set_ylim([-0.2,0.2])\n",
    "        elif Comp == 'Covg':\n",
    "            leg_nd = (o.iloc[0,Sspecies].tolist())\n",
    "            \n",
    "        ax.set_xlabel('Time, t, [s]')\n",
    "        if Comp =='iRates':\n",
    "            ax.set_ylabel(r\"Rates of Production, $R_i$\")\n",
    "            ax.set_title('Rates of production versus Time_ for Simulation_'+ df['Sim_ndex'].iloc[i] +': _'+df['Sim_names'].iloc[0]+'| A:CO* ; B:O*')\n",
    "        elif Comp == 'Covg':\n",
    "            ax.set_ylabel(r\"Coverage, $\\theta_i, [ML]$\")\n",
    "            ax.set_title('Coverages versus Time_for Simulation_'+ df['Sim_ndex'].iloc[i] +': _'+df['Sim_names'].iloc[0]+'| A:CO* ; B:O*')\n",
    "        \n",
    "        \n",
    "        #Extracting MKM results: ------------------------------------------------\n",
    "        mkm_dat = df[[col for col in df if 'MKM_'+Comp in col]].to_numpy() #Extracting MKM comp data as array\n",
    "        Time = df['Time'].to_numpy()\n",
    "            \n",
    "            \n",
    "        #Adding to the plot, MKM result : ------------------------------------------------     \n",
    "        for i in np.arange(len(mkm_dat[0,:])):\n",
    "            ax.plot(Time, mkm_dat[:,i],colors[i]+'-')\n",
    "            ax.set_ylim(bottom=-0.05, top=0.05)\n",
    "        \n",
    "        #Plotting all the legends together\n",
    "        ax.legend([f\"{string}_KMC\" for string in leg_nd]+[f\"{string}_MKM\" for string in leg_nd],fontsize=10, loc='upper right',facecolor='white', edgecolor ='black', framealpha=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af125d4",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.3\"></a> \n",
    "## 2.C  Creating Features:\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da60735",
   "metadata": {},
   "source": [
    "<a id=\"2.3.2\"></a> \n",
    "## 2.C.1  Percent difference\n",
    "<a href=\"#top\">Back to top</a>\n",
    "\n",
    "$$ p_{diff} = \\frac{|r_{MKM}-r_{KMC}|}{\\frac{(r_{MKM}+r_{KMC})}{2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "rx,ry,rz = np.shape(data_KMC_dict['iRates'])\n",
    "P_diff = np.zeros((rx,ry,rz)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68142bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "MKM_values = data_MKM_dict['iRates']\n",
    "KMC_values = data_KMC_dict['iRates']\n",
    "\n",
    "for i in np.arange(rx):\n",
    "    for j in np.arange(ry):\n",
    "        for k in np.arange(rz):\n",
    "            mkmr = KMC_values[i,j,k]\n",
    "            kmcr = MKM_values[i,j,k]      \n",
    "            #Preventing nan\n",
    "            if float(mkmr) == 0:\n",
    "                mkmr = 1e-20\n",
    "            if float(kmcr) == 0:\n",
    "                kmcr = 1e-20\n",
    "            val = abs(mkmr-kmcr)/((mkmr+kmcr)/2) \n",
    "            P_diff[i,j,k] = val\n",
    "            if math.isinf(val) or math.isnan(val):\n",
    "                raise Exception('ERROR: inf or nan is present')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342bd1f",
   "metadata": {},
   "source": [
    "<a id=\"2.3.1\"></a> \n",
    "## 2.C.2  Log ratio correction factor\n",
    "<a href=\"#top\">Back to top</a>\n",
    "\n",
    "$$ corr_{fac} = ln\\frac{r_{KMC}}{r_{MKM}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed76eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rx,ry,rz = np.shape(data_KMC_dict['iRates'])\n",
    "Corr_fac = np.zeros((rx,ry,rz)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "MKM_values = data_MKM_dict['iRates']\n",
    "KMC_values = data_KMC_dict['iRates']\n",
    "\n",
    "for i in np.arange(rx):\n",
    "    for j in np.arange(ry):\n",
    "        for k in np.arange(rz):\n",
    "            num = KMC_values[i,j,k]\n",
    "            den = MKM_values[i,j,k]\n",
    "            #Preventing log(0)\n",
    "            if float(num) == 0:\n",
    "                num = 1e-20\n",
    "            if float(den) == 0:\n",
    "                den = 1e-20\n",
    "                \n",
    "            frac = num/den\n",
    "            #Making sure ln is defined\n",
    "            if float(frac) < 0: #(i.e the rates are either being calculated as consumed versus produced)\n",
    "                frac = abs(frac)\n",
    "                \n",
    "            val = np.log(frac)\n",
    "            Corr_fac[i,j,k] = val\n",
    "            if math.isinf(val) or math.isnan(val):\n",
    "                raise Exception('ERROR: inf or nan is present')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e997b1f2",
   "metadata": {},
   "source": [
    "# Adding Descriptors/Correction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49836d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent Diff\n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df['P_diff_'+spec] = pd.DataFrame(Tensor_To_Array(P_diff))[1+i]\n",
    "\n",
    "#Log Correc\n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    out_df['Corr_fac_'+spec] = pd.DataFrame(Tensor_To_Array(Corr_fac))[1+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc508f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5f7d3",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.5\"></a> \n",
    "## 2.E  Extracting Full X (Feature) and Y(Target) datasets\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f90471",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_columns = out_df.columns.to_list()\n",
    "target_columns = list(filter(lambda x: ('Corr') in x or ('P_diff') in x, All_columns))\n",
    "\n",
    "input_columns = [colmn for colmn in All_columns if colmn not in target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242dc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = out_df[input_columns] #Ignoring the first two columns(index and simulation name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = out_df[['Sim_ndex','Sim_names']+target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928dba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28751e8b",
   "metadata": {},
   "source": [
    "# Removing KMC columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_filter = 'KMC_'\n",
    "\n",
    "# Using the filter function to select columns containing the specified string and drop them\n",
    "filtered_columns = X_all.filter(like=string_to_filter, axis=1)\n",
    "X_all.drop(columns=filtered_columns.columns, inplace=True)\n",
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73ab10",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2.6\"></a> \n",
    "## 2.F  Performing Train/Test X and Y Split datasets\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "p_test = 0.2 #Percent test data\n",
    "print('Percent of test data selected:',p_test*100,'%')\n",
    "\n",
    "\n",
    "max_sim_number = int(X_all[input_columns[0]].iloc[-1]) #MAx_number of simulations present #Count is starting from 0\n",
    "n_test_sim = int(p_test*max_sim_number) #Number of simulations being used as test\n",
    "sim_nums = list(set(X_all['Sim_ndex'])) # List of unique simulation numbers\n",
    "\n",
    "test_sims = random.sample(sim_nums,n_test_sim) #Random sim_numbers for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e11145",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_all.loc[X_all['Sim_ndex'].isin(test_sims)]\n",
    "Y_test = Y_all.loc[Y_all['Sim_ndex'].isin(test_sims)]\n",
    "\n",
    "X_train = X_all[~X_all['Sim_ndex'].isin(test_sims)]\n",
    "Y_train = Y_all[~Y_all['Sim_ndex'].isin(test_sims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making sure no null values are present\n",
    "P_diff = [string for string in All_columns if string.startswith(\"P_diff_\")]#Extracting all different forms of P_diff\n",
    "Y_all[['Sim_ndex'] +P_diff].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING THE SIM_NDEX AND SIM_NAMES COLUMNS\\\n",
    "X_test = X_test.drop(columns=['Sim_ndex','Sim_names'])\n",
    "Y_test = Y_test.drop(columns=['Sim_ndex','Sim_names'])\n",
    "\n",
    "X_train = X_train.drop(columns=['Sim_ndex','Sim_names'])\n",
    "Y_train = Y_train.drop(columns=['Sim_ndex','Sim_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cbb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7930c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ce63b",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"3\"></a> \n",
    "## 3. MODELLING\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8ba3b",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"4\"></a> \n",
    "## 4. Describing Possible Machine Learning Model Algorithms\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_model(algorithm=\"XGBoost\", X_train = X_train, Y_train = Y_train):\n",
    "    \n",
    "    #XGBoost Algorithm\n",
    "    #https://xgboost.readthedocs.io/en/stable/python/python_api.html\n",
    "    if algorithm==\"XGBoost\":  \n",
    "        import xgboost as xgb\n",
    "\n",
    "        reg = xgb.XGBRegressor(booster='gbtree',    \n",
    "                               n_estimators=1500,\n",
    "                               objective='reg:squarederror',\n",
    "                               max_depth=20,\n",
    "                               learning_rate=0.01)\n",
    "        reg.fit(X_train, Y_train,\n",
    "                eval_set=[(X_train, Y_train)],\n",
    "                verbose=False)\n",
    "    \n",
    "    #Artificial Neural Network\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n",
    "    elif algorithm==\"ANN\":\n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        No_H_nodes_per_layer = 128\n",
    "        print('Number of Hidden layer nodes per layer : ',No_H_nodes_per_layer)\n",
    "        No_H_layers = 4\n",
    "        print('Number of Hidden layers: ',No_H_layers)\n",
    "\n",
    "        hidden_layers = No_H_nodes_per_layer*np.ones(No_H_layers) \n",
    "        hidden_layer_sizes = tuple(tuple(int(item) for item in hidden_layers))\n",
    "        reg = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                            activation='relu', \n",
    "                            solver='adam')\n",
    "#                            ,random_state=42, \n",
    "#                             max_iter=300)\n",
    "\n",
    "        reg.fit(X_train, Y_train)\n",
    "    \n",
    "    #K-Nearest Neighbor\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "    elif algorithm==\"KNN\":\n",
    "        from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "        reg = KNeighborsRegressor(n_neighbors=200, weights='distance',p=2)\n",
    "        reg.fit(X_train, Y_train)\n",
    "    \n",
    "    #RandomForest \n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "    elif algorithm=='RandomForest':\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        \n",
    "        reg = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "\n",
    "        reg.fit(X_train, Y_train)\n",
    "        \n",
    "        print('Features:',X_train.columns)\n",
    "        \n",
    "        print('\\nFeature Importance:\\n',reg.feature_importances_) #Shows which features are chosen most when doing splits #gives the most information\n",
    "        \n",
    "    elif algorithm=='DecisionTree':\n",
    "        from sklearn import tree\n",
    "        reg = tree.DecisionTreeRegressor()#criterion='poisson',max_depth=20,min_samples_leaf=10,min_samples_split=20\n",
    "        \n",
    "        reg.fit(X_train, Y_train)\n",
    "        \n",
    "        print('Features:',X_train.columns)\n",
    "        \n",
    "        print('\\nFeature Importance:\\n',reg.feature_importances_) #Shows which features are chosen most when doing splits #gives the most information\n",
    "\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6109149",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"5\"></a> \n",
    "## 5. Selecting the Training Model\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ea71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "######### OPTIONS: 'XGBoost','ANN','KNN','RandomForest'#########\n",
    "################################################################\n",
    "ALGORITHM_NAME = \"XGBoost\"\n",
    "################################################################\n",
    "\n",
    "start_time = time.time()\n",
    "reg = ML_model(algorithm = ALGORITHM_NAME)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"\\nElapsed Model Training Time: \\n\", elapsed_time, \"seconds \\n\", elapsed_time/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestNo = '24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d292de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_File_Name ='../Test_Data_Lateral/Test_'+TestNo+'/KMC_NonDynamic_Data_iCovg_iRates_Test_'+TestNo+'.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45719a7d",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"6\"></a> \n",
    "## 6. Importing External/Experimental Data to be used in the model\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69468c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "KMC_Data_EXP = pd.read_csv(Test_File_Name)\n",
    "KMC_Data_EXP_rates= KMC_Data_EXP.iloc[:,-n_gas_species:] #To be used to later to compare and asses ML prediction results\n",
    "\n",
    "print('KMC Input Data:\\n\\n',KMC_Data_EXP.head())\n",
    "#Creating repeated init covs matrix to make up X_Input entry for ML\n",
    "test_data_ini_cov = KMC_Data_EXP.iloc[0,1:5].values\n",
    "test_data_time_interv = KMC_Data_EXP.iloc[:,0].values\n",
    "matrix_test_data_ini_cov = np.empty((len(test_data_time_interv),len(test_data_ini_cov)))\n",
    "for i in np.arange(len(test_data_time_interv)):\n",
    "    matrix_test_data_ini_cov[i] = test_data_ini_cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df[out_df['Sim_names'] == 'Sim_A_0_B_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10d9bf",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"6.1\"></a> \n",
    "## 6.A Generating corresponding MF-MKModel\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00691f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from main import *\n",
    "MKM_test_inp = MKModel('Atomic_sw.csv','Stoich_sw.csv','Param_sw.csv')\n",
    "Tot_Pres = 1e-4\n",
    "Mol_frac_O2 = 0.1\n",
    "Mol_frac_CO = 1e-5\n",
    "Mol_frac_CO2 = 0\n",
    "MKM_test_inp.set_rxnconditions(Pr=[(Tot_Pres*Mol_frac_O2),(Tot_Pres*Mol_frac_CO), Mol_frac_CO2]) #From KMC #Make sure it matches 02 CO CO2\n",
    "# MKM_test_inp.set_rxnconditions(Pr = list(float(i) for i in MKM.P) )\n",
    "MKM_test_inp.set_limits_of_integration(Ti=float(KMC_Data_EXP['Time'].head(1)),Tf=float(KMC_Data_EXP['Time'].tail(1)))\n",
    "MKM_test_inp.ODE_Tolerances(Dplace=50,reltol=1e-8,abstol=1e-8)\n",
    "# MKM_test_inp.k = params #From fitting or external\n",
    "MKM_test_inp.k= MKM.k\n",
    "MKM_Covg_test_inp = np.zeros((len(test_data_time_interv),len(test_data_ini_cov))) \n",
    "MKM_Rates_test_inp = np.zeros((len(test_data_time_interv),n_gas_species)) \n",
    "\n",
    "MKM_test_inp.set_initial_coverages(init=test_data_ini_cov)\n",
    "\n",
    "test_sola,_ = MKM_test_inp.solve_coverage(Tf_eval=test_data_time_interv,plot=False)\n",
    "MKM_Covg_test_inp = test_sola #Coverage profile matrix\n",
    "\n",
    "test_solb,_ = MKM_test_inp.solve_rate_production(Tf_eval=test_data_time_interv,plot=False)\n",
    "MKM_Rates_test_inp = test_solb[:,0:n_gas_species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_surf_name = KMC_Data_EXP.columns.to_list()[1:n_surf_species+1]\n",
    "Exp_gas_name = [i[-2:] for i in KMC_Data_EXP.columns.to_list()[n_surf_species+1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_input = pd.DataFrame()\n",
    "\n",
    "#Adding initial coverages\n",
    "surf_names = Exp_surf_name\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    Test_input['Init_Covg_'+spec] = pd.DataFrame(matrix_test_data_ini_cov)[i]\n",
    "\n",
    "#Adding Time\n",
    "Test_input['Time'] = pd.DataFrame(test_data_time_interv)\n",
    "\n",
    "#Adding coverage profiles of surface species\n",
    "surf_names = Exp_surf_name\n",
    "for i in np.arange(n_surf_species):\n",
    "    spec = surf_names[i]\n",
    "    Test_input['MKM_Covg_'+spec] = pd.DataFrame(MKM_Covg_test_inp)[i]\n",
    "    \n",
    "#Adding iRates profiles of gaseous species\n",
    "gs_names = (o.iloc[0,Gspecies].tolist())\n",
    "for i in np.arange(n_gas_species):\n",
    "    spec = gs_names[i]\n",
    "    Test_input['MKM_iRates_'+spec] = pd.DataFrame(MKM_Rates_test_inp)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1bff7",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"6.2\"></a> \n",
    "## 6.B Predicting Machine-Learned Mean-Field Corrections\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2eadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95650e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpful for XGBOOST readability\n",
    "Test_input['MKM_iRates_CO2'] = Test_input['MKM_iRates_CO2'].astype(float)\n",
    "Test_input['MKM_iRates_O2'] = Test_input['MKM_iRates_O2'].astype(float)\n",
    "Test_input['MKM_iRates_CO'] = Test_input['MKM_iRates_CO'].astype(float)\n",
    "\n",
    "Test_output = reg.predict(Test_input) #FITTING\n",
    "\n",
    "\n",
    "Pred_corr = Test_output[:,-len(Exp_gas_name):] #extracting correction factors  #O2 #CO #CO2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611ad01",
   "metadata": {},
   "source": [
    "<a id=\"6.3\"></a> \n",
    "## 6.C ML Correction to MF-MKModel\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b24af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating extracted ML predicted rates\n",
    "ML_Rates_pred = np.zeros((len(test_data_time_interv),len(Exp_gas_name)))  #O2, #CO, #CO2\n",
    "for i in np.arange(np.shape(ML_Rates_pred)[0]):\n",
    "    for j in np.arange(np.shape(ML_Rates_pred)[1]):\n",
    "        ML_Rates_pred[i,j] = MKM_Rates_test_inp[i,j]*np.exp(Pred_corr[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c665f5e",
   "metadata": {},
   "source": [
    "<a id=\"6.4\"></a> \n",
    "## 6.D Evaluating the ML model prediction\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#Calculating the root mean squared of the test set\n",
    "print('Root Mean Squared Error:\\n',sqrt(mean_squared_error(KMC_Data_EXP_rates, ML_Rates_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fadac4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KMC_Data_EXP_rates.values[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436e12f",
   "metadata": {},
   "source": [
    "<a id=\"6.5\"></a> \n",
    "## 6.E Plotting\n",
    "<a href=\"#top\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776a9b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(test_data_time_interv, KMC_Data_EXP_rates.values[:,0],'r*', label='O2_kMC')        \n",
    "plt.plot(test_data_time_interv, KMC_Data_EXP_rates.values[:,1],'g*', label='CO_kMC') \n",
    "plt.plot(test_data_time_interv, KMC_Data_EXP_rates.values[:,2], 'b*', label='CO2_kMC') \n",
    "\n",
    "plt.plot(test_data_time_interv, MKM_Rates_test_inp[:,0],'ro', label='O2_MKM')        \n",
    "plt.plot(test_data_time_interv, MKM_Rates_test_inp[:,1],'go', label='CO_MKM') \n",
    "plt.plot(test_data_time_interv, MKM_Rates_test_inp[:,2], 'bo', label='CO2_MKM') \n",
    "\n",
    "plt.plot(test_data_time_interv, ML_Rates_pred[:,0],'r-', label='O2_ML')        \n",
    "plt.plot(test_data_time_interv, ML_Rates_pred[:,1],'g-', label='CO_ML') \n",
    "plt.plot(test_data_time_interv, ML_Rates_pred[:,2], 'b-', label='CO2_ML') \n",
    "\n",
    "plt.xlabel('Time, s')\n",
    "plt.ylabel(\"Rates_production, $r$\")\n",
    "plt.title('ML_rate_correction_Results')\n",
    "# plt.ylim([-0.004,0.004])\n",
    "plt.legend(fontsize=5, loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f36bd",
   "metadata": {},
   "source": [
    "## Parity Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rates\n",
    "plt.figure()\n",
    "# Draw a y=x line\n",
    "plt.axline((0, 0), slope=1,color = 'k',linestyle='--')\n",
    "plt.plot(KMC_Data_EXP_rates.values[:,0],ML_Rates_pred[:,0],'r*',label='O2')\n",
    "plt.plot(KMC_Data_EXP_rates.values[:,1],ML_Rates_pred[:,1],'g*', label='CO')\n",
    "plt.plot(KMC_Data_EXP_rates.values[:,2],ML_Rates_pred[:,2],'b*', label='CO2')\n",
    "plt.xlabel(r'Rates_Test_'+TestNo+' (experimental)')\n",
    "plt.title('Parity Plot_Test_'+TestNo)\n",
    "plt.ylabel(\"Rates_Test_\"+TestNo+\" (fit)\")\n",
    "# plt.ylim([-0.005,0.005])\n",
    "# plt.xlim([-0.005,0.005])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756ff57",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"7\"></a> \n",
    "## 7. Exploring and Evaluating possible ML options\n",
    "<a href=\"#top\">Back to top</a>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db7cf7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #%matplotlib notebook\n",
    "# import time\n",
    "# from math import sqrt\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# algs = ['ANN','KNN','RandomForest','DecisionTree']\n",
    "# rmse_vec = []\n",
    "# for v in np.arange(len(algs)):\n",
    "    \n",
    "#     print(\"-\"*50)\n",
    "#     print('Algorithm:',algs[v],'\\n')\n",
    "    \n",
    "#     tart_time = time.time()  \n",
    "#     reg = ML_model(algorithm=algs[v])\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     elapsed_time = end_time - start_time\n",
    "#     print(\"\\nElapsed Model Training Time: \\n\", elapsed_time, \"seconds \\n\", elapsed_time/60, \"minutes\")\n",
    "    \n",
    "#     Test_output = reg.predict(Test_input)\n",
    "\n",
    "#     Pred_corr = Test_output[:,-3:] #extracting correction factors #CO #O2 #CO2\n",
    "    \n",
    "#     #Calculating extracted ML predicted rates\n",
    "#     ML_Rates_pred = np.zeros((len(test_data_time_interv),3)) #CO, O2, CO2\n",
    "#     for i in np.arange(np.shape(ML_Rates_pred)[0]):\n",
    "#         for j in np.arange(np.shape(ML_Rates_pred)[1]):\n",
    "#             ML_Rates_pred[i,j] = MKM_Rates_test_inp[i,j]*np.exp(Pred_corr[i,j])\n",
    "    \n",
    "#     #Calculating the root mean squared of the test set\n",
    "#     rmse = sqrt(mean_squared_error(KMC_Data_EXP_rates, ML_Rates_pred))\n",
    "#     print('\\nRoot Mean Squared Error when using',algs[v],':\\n',rmse)\n",
    "#     rmse_vec.append(rmse)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(test_data_time_interv, KMC_Data_EXP_rates.values[:,0],'r*', label='O2_kMC')        \n",
    "#     plt.plot(test_data_time_interv, KMC_Data_EXP_rates.values[:,1],'g*', label='CO_kMC') \n",
    "#     plt.plot(test_data_time_interv, KMC_Data_EXP_rates.values[:,2], 'b*', label='CO2_kMC') \n",
    "\n",
    "#     plt.plot(test_data_time_interv, MKM_Rates_test_inp[:,0],'ro', label='O2_MKM')        \n",
    "#     plt.plot(test_data_time_interv, MKM_Rates_test_inp[:,1],'go', label='CO_MKM') \n",
    "#     plt.plot(test_data_time_interv, MKM_Rates_test_inp[:,2], 'bo', label='CO2_MKM') \n",
    "\n",
    "#     plt.plot(test_data_time_interv, ML_Rates_pred[:,0],'r-', label='O2_ML')        \n",
    "#     plt.plot(test_data_time_interv, ML_Rates_pred[:,1],'g-', label='CO_ML') \n",
    "#     plt.plot(test_data_time_interv, ML_Rates_pred[:,2], 'b-', label='CO2_ML') \n",
    "\n",
    "#     plt.xlabel('Time, s')\n",
    "#     plt.ylabel(\"Rates_production, $r$\")\n",
    "#     plt.title('Algorithm: {}'.format(algs[v]))\n",
    "#     plt.legend(fontsize=5, loc='best')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The ML model giving the smallest rmse of\", rmse_vec[np.argmin(rmse_vec)],\"is : \\n\",algs[np.argmin(rmse_vec)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7cd614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e3c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0030e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
